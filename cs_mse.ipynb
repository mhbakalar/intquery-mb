{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sequence data from cryptic seq experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import genome_utils\n",
    "import genomepy\n",
    "\n",
    "genomic_reference_file = '../data/references/hg38.fa'\n",
    "\n",
    "# Key for data label\n",
    "label_key = 'count'\n",
    "\n",
    "# Load cryptic sites\n",
    "sites = pd.read_csv('./data/gt_cryptic.csv')\n",
    "sites = genome_utils.fetch_genomic_sites(sites, genomic_reference_file)\n",
    "\n",
    "hits = sites['sequence']\n",
    "hit_count = len(hits)\n",
    "if label_key == '':\n",
    "    hits_labels = np.ones(len(sites))\n",
    "else:\n",
    "    hits_labels = sites[label_key]\n",
    "\n",
    "# Length of a cryptic site\n",
    "seq_length = len(hits[0])\n",
    "\n",
    "# Generate random decoy sequences\n",
    "genome = genomepy.genome.Genome(genomic_reference_file)\n",
    "samples = genome.get_random_sequences(n=hit_count, length=seq_length-1, max_n=0)\n",
    "decoys = pd.Series(list(map(lambda row: genome.get_seq(*row).seq.upper(), samples)))\n",
    "decoys_labels = np.zeros(len(decoys))\n",
    "\n",
    "# Set dinucleotide to NN in both hits and decoys\n",
    "dn_start = int(seq_length/2)\n",
    "hits = hits.apply(lambda seq: seq[:dn_start-1] + 'NN' + seq[dn_start+1:])\n",
    "decoys = decoys.apply(lambda seq: seq[:dn_start-1] + 'NN' + seq[dn_start+1:])\n",
    "\n",
    "# Concatenate hits and decoys\n",
    "sequences = np.hstack([hits, decoys])\n",
    "labels = np.hstack([hits_labels, decoys_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import mlp\n",
    "from datasets import one_hot\n",
    "\n",
    "vocab_size = 5\n",
    "hidden_size = 46*5\n",
    "n_hidden = 2\n",
    "train_test_split = 0.8\n",
    "\n",
    "dataset = one_hot.Dataset(sequences, labels, vocab_size=vocab_size)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Test and train data split\n",
    "train_size = int(train_test_split*len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# Build model\n",
    "model = mlp.Model(input_size=seq_length*vocab_size, hidden_size=hidden_size, output_size=1, n_hidden=n_hidden)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/20\n",
      "-------------\n",
      "Train loss: 1145.9858812464124\n",
      "Train Accuracy: 0.669374591770085\n",
      "Train F1 Score: 0.6004841317240357\n",
      "Val loss: 943.1357568750778\n",
      "Val Accuracy: 0.6992161985630307\n",
      "Val F1 Score: 0.6214177687544231\n",
      "-------------\n",
      "\n",
      "Epoch 1/20\n",
      "-------------\n",
      "Train loss: 1094.2839646813297\n",
      "Train Accuracy: 0.643819399085565\n",
      "Train F1 Score: 0.5597289360428788\n",
      "Val loss: 949.7584421336651\n",
      "Val Accuracy: 0.6559438275636839\n",
      "Val F1 Score: 0.572962259619096\n",
      "-------------\n",
      "\n",
      "Epoch 2/20\n",
      "-------------\n",
      "Train loss: 1085.6378298795566\n",
      "Train Accuracy: 0.6190806662312214\n",
      "Train F1 Score: 0.541631998095717\n",
      "Val loss: 968.5542008628448\n",
      "Val Accuracy: 0.6319399085564991\n",
      "Val F1 Score: 0.5454174024571612\n",
      "-------------\n",
      "\n",
      "Epoch 3/20\n",
      "-------------\n",
      "Train loss: 1044.8476956550508\n",
      "Train Accuracy: 0.6197338340953625\n",
      "Train F1 Score: 0.5408677734461498\n",
      "Val loss: 999.3091360206405\n",
      "Val Accuracy: 0.6193664271717831\n",
      "Val F1 Score: 0.5301880552442674\n",
      "-------------\n",
      "\n",
      "Epoch 4/20\n",
      "-------------\n",
      "Train loss: 1019.150117921378\n",
      "Train Accuracy: 0.6252041149575441\n",
      "Train F1 Score: 0.5459409126312719\n",
      "Val loss: 1027.64711358957\n",
      "Val Accuracy: 0.6182233834095362\n",
      "Val F1 Score: 0.5282287480537499\n",
      "-------------\n",
      "\n",
      "Epoch 5/20\n",
      "-------------\n",
      "Train loss: 953.7169674380291\n",
      "Train Accuracy: 0.6259797517962117\n",
      "Train F1 Score: 0.5442190784419781\n",
      "Val loss: 1050.1582388753693\n",
      "Val Accuracy: 0.6221423905943828\n",
      "Val F1 Score: 0.5348257343650469\n",
      "-------------\n",
      "\n",
      "Epoch 6/20\n",
      "-------------\n",
      "Train loss: 911.4197728848644\n",
      "Train Accuracy: 0.6084666884389288\n",
      "Train F1 Score: 0.5239881052849255\n",
      "Val loss: 1073.9901742873092\n",
      "Val Accuracy: 0.6022207707380797\n",
      "Val F1 Score: 0.508384272030093\n",
      "-------------\n",
      "\n",
      "Epoch 7/20\n",
      "-------------\n",
      "Train loss: 843.5173352516351\n",
      "Train Accuracy: 0.6134062704114958\n",
      "Train F1 Score: 0.527671676737905\n",
      "Val loss: 1115.0159121534477\n",
      "Val Accuracy: 0.6321032005225343\n",
      "Val F1 Score: 0.5463249758674555\n",
      "-------------\n",
      "\n",
      "Epoch 8/20\n",
      "-------------\n",
      "Train loss: 736.7386306211469\n",
      "Train Accuracy: 0.6122632266492488\n",
      "Train F1 Score: 0.5234184131318241\n",
      "Val loss: 1221.1581311756745\n",
      "Val Accuracy: 0.5785434356629654\n",
      "Val F1 Score: 0.4763113269467152\n",
      "-------------\n",
      "\n",
      "Epoch 9/20\n",
      "-------------\n",
      "Train loss: 638.209631584643\n",
      "Train Accuracy: 0.5989141084258655\n",
      "Train F1 Score: 0.506026558039663\n",
      "Val loss: 1194.896242648363\n",
      "Val Accuracy: 0.5867080339647289\n",
      "Val F1 Score: 0.4875499957414897\n",
      "-------------\n",
      "\n",
      "Epoch 10/20\n",
      "-------------\n",
      "Train loss: 553.0462019755541\n",
      "Train Accuracy: 0.6023432397126062\n",
      "Train F1 Score: 0.5098571741536662\n",
      "Val loss: 1220.145995563517\n",
      "Val Accuracy: 0.5645003265839321\n",
      "Val F1 Score: 0.4554829287906205\n",
      "-------------\n",
      "\n",
      "Epoch 11/20\n",
      "-------------\n",
      "Train loss: 458.24803851898906\n",
      "Train Accuracy: 0.5838912475506205\n",
      "Train F1 Score: 0.4854623846770431\n",
      "Val loss: 1115.1423867139965\n",
      "Val Accuracy: 0.5889941214892227\n",
      "Val F1 Score: 0.4902033624300165\n",
      "-------------\n",
      "\n",
      "Epoch 12/20\n",
      "-------------\n",
      "Train loss: 403.8468619327477\n",
      "Train Accuracy: 0.5921783148269105\n",
      "Train F1 Score: 0.49605139661456904\n",
      "Val loss: 1130.2898887870833\n",
      "Val Accuracy: 0.5894839973873286\n",
      "Val F1 Score: 0.4911946171960173\n",
      "-------------\n",
      "\n",
      "Epoch 13/20\n",
      "-------------\n",
      "Train loss: 404.1149997343516\n",
      "Train Accuracy: 0.5960564990202482\n",
      "Train F1 Score: 0.5019475752273517\n",
      "Val loss: 1037.3845533458516\n",
      "Val Accuracy: 0.5796864794252122\n",
      "Val F1 Score: 0.4777403178905237\n",
      "-------------\n",
      "\n",
      "Epoch 14/20\n",
      "-------------\n",
      "Train loss: 380.53152745230705\n",
      "Train Accuracy: 0.608874918354017\n",
      "Train F1 Score: 0.5184095054836707\n",
      "Val loss: 1099.4063264510285\n",
      "Val Accuracy: 0.5822991508817766\n",
      "Val F1 Score: 0.4808951857689863\n",
      "-------------\n",
      "\n",
      "Epoch 15/20\n",
      "-------------\n",
      "Train loss: 335.97875879483183\n",
      "Train Accuracy: 0.6004245591116917\n",
      "Train F1 Score: 0.5082181307655186\n",
      "Val loss: 1138.4232816795509\n",
      "Val Accuracy: 0.6004245591116917\n",
      "Val F1 Score: 0.5077562782751533\n",
      "-------------\n",
      "\n",
      "Epoch 16/20\n",
      "-------------\n",
      "Train loss: 311.0792005363628\n",
      "Train Accuracy: 0.607078706727629\n",
      "Train F1 Score: 0.5191082831020241\n",
      "Val loss: 976.687458230493\n",
      "Val Accuracy: 0.6288373612018289\n",
      "Val F1 Score: 0.5500510779008893\n",
      "-------------\n",
      "\n",
      "Epoch 17/20\n",
      "-------------\n",
      "Train loss: 302.0129552842276\n",
      "Train Accuracy: 0.6482282821685174\n",
      "Train F1 Score: 0.5686927834931876\n",
      "Val loss: 983.0205799251174\n",
      "Val Accuracy: 0.6554539516655781\n",
      "Val F1 Score: 0.5762018626978642\n",
      "-------------\n",
      "\n",
      "Epoch 18/20\n",
      "-------------\n",
      "Train loss: 324.40402573385995\n",
      "Train Accuracy: 0.6656188765512737\n",
      "Train F1 Score: 0.588105085647008\n",
      "Val loss: 973.0150292022154\n",
      "Val Accuracy: 0.6789679947746571\n",
      "Val F1 Score: 0.6040871805997572\n",
      "-------------\n",
      "\n",
      "Epoch 19/20\n",
      "-------------\n",
      "Train loss: 267.4881709713693\n",
      "Train Accuracy: 0.6770901371652515\n",
      "Train F1 Score: 0.6000508584155763\n",
      "Val loss: 1101.3239746236552\n",
      "Val Accuracy: 0.6851730894839974\n",
      "Val F1 Score: 0.6103449569778627\n",
      "-------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "# training loop\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_preds, train_targets = [], []\n",
    "\n",
    "    # Training Phase\n",
    "    for i, (data, target) in enumerate(train_dataloader):\n",
    "        output = model(data).flatten()\n",
    "\n",
    "        # Convert output probabilities to predicted class\n",
    "        preds = (output > 0.5).float()\n",
    "        train_preds.extend(preds.tolist())\n",
    "        train_targets.extend(target.tolist())\n",
    "\n",
    "        loss = loss_fn(output, target.float())\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_accuracy = accuracy_score(train_targets, train_preds)\n",
    "    train_f1 = f1_score(train_targets, train_preds, average='weighted')\n",
    "\n",
    "    print(f\"Epoch {epoch}/{epochs}\")\n",
    "    print(f\"-------------\")\n",
    "    print(f\"Train loss: {train_loss/len(train_dataloader)}\")\n",
    "    print(f\"Train Accuracy: {train_accuracy}\")\n",
    "    print(f\"Train F1 Score: {train_f1}\")\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_preds, val_targets = [], []\n",
    "\n",
    "    # Validation Phase\n",
    "    with torch.no_grad():\n",
    "        for i, (data, target) in enumerate(val_dataloader):\n",
    "            output = model(data).flatten()\n",
    "\n",
    "            # Convert output probabilities to predicted class\n",
    "            preds = (output > 0.5).float()\n",
    "            val_preds.extend(preds.tolist())\n",
    "            val_targets.extend(target.tolist())\n",
    "\n",
    "            loss = loss_fn(output, target.float())\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        val_accuracy = accuracy_score(val_targets, val_preds)\n",
    "        val_f1 = f1_score(val_targets, val_preds, average='weighted')\n",
    "\n",
    "    print(f\"Val loss: {val_loss/len(val_dataloader)}\")\n",
    "    print(f\"Val Accuracy: {val_accuracy}\")\n",
    "    print(f\"Val F1 Score: {val_f1}\")\n",
    "    print(f\"-------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and plot correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 52900 into shape (46,5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogomaker\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m pyplot \u001b[39mas\u001b[39;00m plt\n\u001b[0;32m----> 3\u001b[0m prob_weight_matrix \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(model\u001b[39m.\u001b[39mfc_layers[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mreshape(\u001b[39m46\u001b[39m,\u001b[39m5\u001b[39m), columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mA\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mT\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mG\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mN\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m logomaker\u001b[39m.\u001b[39mLogo(prob_weight_matrix, color_scheme\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mclassic\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 52900 into shape (46,5)"
     ]
    }
   ],
   "source": [
    "import logomaker\n",
    "from matplotlib import pyplot as plt\n",
    "prob_weight_matrix = pd.DataFrame(model.fc_layers[0].weight.detach().numpy().reshape(46,5), columns=['A','T','C','G','N'])\n",
    "logomaker.Logo(prob_weight_matrix, color_scheme='classic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
