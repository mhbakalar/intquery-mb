{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sequence data from cryptic seq experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BINS = 2\n",
    "SEQUENCE = 'seq'\n",
    "VALUE = 'count'\n",
    "\n",
    "# Load data from cryptic seq experiment\n",
    "sites_xl = pd.ExcelFile('./data/TB000208a.outputs.xlsx')\n",
    "sites_xl.sheet_names\n",
    "training_sheets = ['GT-Rep1-N7_S1','GT-Rep2-N7_S2','GT-Rep3-N7_S3']\n",
    "sheets = []\n",
    "for name in training_sheets:\n",
    "    sheets.append(sites_xl.parse(name))\n",
    "sites = pd.concat(sheets).reset_index()\n",
    "\n",
    "# Only take canonical dinucleotide insertions\n",
    "sites = sites[sites['genome_dinucleotide'] == sites['donor'].str.slice(5,7)]\n",
    "\n",
    "# Average count at identical sites\n",
    "sites = sites.groupby(['seq'], as_index=False).sum(numeric_only=False)\n",
    "sites[VALUE] = np.log(sites[VALUE])\n",
    "\n",
    "# Bin the counts into N bins\n",
    "sites[VALUE], bins = pd.cut(sites[VALUE], BINS, labels=False, retbins=True)\n",
    "\n",
    "# Compute class frequencies for weighting\n",
    "class_sample_count = np.array([len(np.where(sites[VALUE] == c)[0]) for c in np.unique(sites[VALUE])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into left and right\n",
    "complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A'}\n",
    "reverse_complement = lambda x: \"\".join(complement.get(base, base) for base in reversed(x))\n",
    "\n",
    "left = sites[SEQUENCE].str.slice(0,22)\n",
    "left_rc = left.apply(reverse_complement)\n",
    "right = sites[SEQUENCE].str.slice(24,)\n",
    "right_rc = right.apply(reverse_complement)\n",
    "\n",
    "sites['left'] = left\n",
    "sites['right'] = right_rc\n",
    "\n",
    "combined_sites = pd.concat([pd.DataFrame({\"seq\": sites[key], \"value\": sites[VALUE]}) for key in ['left', 'right']]).reset_index()\n",
    "\n",
    "# Use symmetric sites as data input\n",
    "sites = combined_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import genome_utils\n",
    "import genomepy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "genomic_reference_file = '../data/references/hg38.fa'\n",
    "\n",
    "# Extract cryptic sites\n",
    "hits = sites[SEQUENCE]\n",
    "hit_count = len(hits)\n",
    "hits_labels = sites['value']\n",
    "\n",
    "# Length of a cryptic site\n",
    "seq_length = len(hits[0])\n",
    "\n",
    "# Generate random decoy sequences\n",
    "genome = genomepy.genome.Genome(genomic_reference_file)\n",
    "samples = genome.get_random_sequences(n=hit_count, length=seq_length-1, max_n=0)\n",
    "decoys = pd.Series(list(map(lambda row: genome.get_seq(*row).seq.upper(), samples)))\n",
    "decoys_labels = np.zeros(len(decoys))\n",
    "\n",
    "# Concatenate hits and decoys\n",
    "#sequences = np.hstack([hits, decoys])\n",
    "#labels = np.hstack([hits_labels, decoys_labels])\n",
    "\n",
    "# Positive data only\n",
    "sequences = hits.values\n",
    "labels = hits_labels.values\n",
    "\n",
    "# Set dinucleotide to NN in both hits and decoys\n",
    "#dn_start = int(seq_length/2)\n",
    "#hits = hits.apply(lambda seq: seq[:dn_start-1] + 'NN' + seq[dn_start+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import mlp\n",
    "from datasets import one_hot\n",
    "\n",
    "vocab_size = 5\n",
    "hidden_size = 1024\n",
    "n_hidden = 2\n",
    "train_test_split = 0.8\n",
    "\n",
    "dataset = one_hot.Dataset(sequences, labels, vocab_size=vocab_size, output_size=BINS)\n",
    "\n",
    "# Sample weights based on label and class frequency\n",
    "weight = 1. / class_sample_count\n",
    "samples_weight = np.array([weight[t] for t in labels])\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "\n",
    "# Test and train data split\n",
    "train_size = int(train_test_split*len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Weighted random sampler for upsampling minority class\n",
    "train_sample_weights = samples_weight[train_dataset.indices]\n",
    "sampler = torch.utils.data.WeightedRandomSampler(train_sample_weights, len(train_sample_weights), replacement=True)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=8, sampler=sampler)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "# Build model\n",
    "model = mlp.Model(input_size=seq_length*vocab_size, hidden_size=hidden_size, output_size=BINS, n_hidden=n_hidden, dropout=0.25)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10\n",
      "-------------\n",
      "Train loss: 0.4736319305555807\n",
      "Train accuracy: 0.7717420390687717\n",
      "Val loss: 0.4761919917758931\n",
      "Val accuracy: 0.756532141283133\n",
      "-------------\n",
      "\n",
      "Epoch 1/10\n",
      "-------------\n",
      "Train loss: 0.3021833679382109\n",
      "Train accuracy: 0.8730186214169907\n",
      "Val loss: 0.3938070429711003\n",
      "Val accuracy: 0.85651325316376\n",
      "-------------\n",
      "\n",
      "Epoch 2/10\n",
      "-------------\n",
      "Train loss: 0.22361921375450194\n",
      "Train accuracy: 0.9110170158510287\n",
      "Val loss: 0.4696190122670396\n",
      "Val accuracy: 0.85651325316376\n",
      "-------------\n",
      "\n",
      "Epoch 3/10\n",
      "-------------\n",
      "Train loss: 0.17443364747454768\n",
      "Train accuracy: 0.9319523367281084\n",
      "Val loss: 0.4154841466612931\n",
      "Val accuracy: 0.9063149279103444\n",
      "-------------\n",
      "\n",
      "Epoch 4/10\n",
      "-------------\n",
      "Train loss: 0.14624788479925208\n",
      "Train accuracy: 0.9442616757701208\n",
      "Val loss: 0.48684790693992863\n",
      "Val accuracy: 0.8891267392809923\n",
      "-------------\n",
      "\n",
      "Epoch 5/10\n",
      "-------------\n",
      "Train loss: 0.12840466727169958\n",
      "Train accuracy: 0.9529978435045412\n",
      "Val loss: 0.5419871926761328\n",
      "Val accuracy: 0.9005855317005603\n",
      "-------------\n",
      "\n",
      "Epoch 6/10\n",
      "-------------\n",
      "Train loss: 0.11384825623417588\n",
      "Train accuracy: 0.95759416959184\n",
      "Val loss: 0.5438529386101593\n",
      "Val accuracy: 0.9130516904866839\n",
      "-------------\n",
      "\n",
      "Epoch 7/10\n",
      "-------------\n",
      "Train loss: 0.10839135877999936\n",
      "Train accuracy: 0.9603960396039604\n",
      "Val loss: 0.6305854000282838\n",
      "Val accuracy: 0.9168293143612668\n",
      "-------------\n",
      "\n",
      "Epoch 8/10\n",
      "-------------\n",
      "Train loss: 0.09761269065172813\n",
      "Train accuracy: 0.9637488391128461\n",
      "Val loss: 0.6442741351635853\n",
      "Val accuracy: 0.9020965812503935\n",
      "-------------\n",
      "\n",
      "Epoch 9/10\n",
      "-------------\n",
      "Train loss: 0.09363050681204642\n",
      "Train accuracy: 0.9660627429992602\n",
      "Val loss: 0.7238076831209069\n",
      "Val accuracy: 0.9130516904866839\n",
      "-------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "epochs = 10\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# training loop\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_preds, train_targets = [], []\n",
    "\n",
    "    # Training Phase\n",
    "    for i, (data, target) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "        # Convert output probabilities to predicted class\n",
    "        preds = output.float()\n",
    "        train_preds.extend(preds)\n",
    "        train_targets.extend(target)\n",
    "\n",
    "        loss = loss_fn(output, target.float())\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_error = accuracy_score(torch.argmax(torch.stack(train_targets), 1), torch.argmax(torch.stack(train_preds), 1))\n",
    "\n",
    "    print(f\"Epoch {epoch}/{epochs}\")\n",
    "    print(f\"-------------\")\n",
    "    print(f\"Train loss: {train_loss/len(train_dataloader)}\")\n",
    "    print(f\"Train accuracy: {train_error}\")\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_preds, val_targets = [], []\n",
    "\n",
    "    # Validation Phase\n",
    "    with torch.no_grad():\n",
    "        for i, (data, target) in enumerate(val_dataloader):\n",
    "            output = model(data)\n",
    "\n",
    "            # Convert output probabilities to predicted class\n",
    "            preds = output.float()\n",
    "            val_preds.extend(preds)\n",
    "            val_targets.extend(target)\n",
    "\n",
    "            loss = loss_fn(output, target.float())\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        val_error = accuracy_score(torch.argmax(torch.stack(val_targets), 1), torch.argmax(torch.stack(val_preds), 1))\n",
    "\n",
    "    print(f\"Val loss: {val_loss/len(val_dataloader)}\")\n",
    "    print(f\"Val accuracy: {val_error}\")\n",
    "    print(f\"-------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Iterate over the DataLoader and make predictions\n",
    "val_inputs = []\n",
    "val_targets = []\n",
    "val_preds = []\n",
    "with torch.no_grad():\n",
    "    for i, (data, target) in enumerate(val_dataloader):\n",
    "        output = model(data)\n",
    "\n",
    "        # Convert output probabilities to predicted class\n",
    "        preds = output.float()\n",
    "\n",
    "        # Save prediction data\n",
    "        val_inputs.extend(data.tolist())\n",
    "        val_preds.extend(preds)\n",
    "        val_targets.extend(target)\n",
    "\n",
    "# Translate inputs\n",
    "trans_dict = {0:'A',1:'T',2:'C',3:'G',4:'N'}\n",
    "translate_func = lambda x: ''.join([trans_dict[y] for y in x])\n",
    "\n",
    "inputs = np.argmax(val_inputs, axis=2)\n",
    "inputs = [translate_func(x) for x in inputs]\n",
    "\n",
    "# Argmax targets and predictions\n",
    "val_targets = torch.argmax(torch.stack(val_targets), 1)\n",
    "val_preds = torch.argmax(torch.stack(val_preds), 1)\n",
    "\n",
    "predictions = pd.DataFrame({\"seq\":inputs, \"targets\":val_targets, \"outputs\": val_preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAGGATTGCTTGAACCTAGGAG\n",
      "TGAATGTTTCTAGACAAAAGTG\n",
      "AATGGTGGTTATCACAACGGCA\n",
      "TGTTCAGAACCTCACCATTGAG\n",
      "TGCATGGGTTGTGGCAGCGGAA\n",
      "CCGCCTGGCTTCACCCACAGCC\n",
      "GGTTGGTTTTGCTGTCTCAGGG\n",
      "CCCCCTTTTTTATACATCTGAT\n",
      "TTCCTTAGCTTCCCCAGCTGGA\n",
      "AAAACAATTTTTAATAATAGAG\n",
      "ACAGCAGACAGCAACAACAGCA\n",
      "TACGTGATTTCTGAGCACTGAA\n",
      "CCTTTTACTCTTCACAACGGAG\n",
      "ACAGACTTGCTTTCACATGGAG\n",
      "CTTTGAAGCCTTGACTACAGAG\n",
      "AGTTGCCATCCCCTCAATGGAG\n",
      "GAACATTTCCATCACCACAGAA\n",
      "CAGCTTGCTCTTGATAACTGCG\n",
      "AGAAAGTTTGTTTCCTACAGAG\n",
      "TTTATGTATTTCTAGATTAGAG\n",
      "CACTTGAATCCAGGCGACAGAG\n",
      "AGTCAGCTTTCTGTCAACTGCA\n",
      "CCTGCAATCTTAGCCAACAGTG\n",
      "TAATTTTCCTTACGCAACGGTA\n",
      "GGCTGTGGTTTGCACAGCTGAT\n",
      "CACTTGAATCTGGGAGGCGGAG\n",
      "GCAATTCATTTCTGCAATTGCT\n",
      "TGGGGTCGCTTCACCAGCAGAA\n",
      "GAAGGTGCTTCCGGCCACAGAG\n",
      "TGGCATGATCTCAGTCACTGCA\n",
      "CCCCGGTTTTCTGTCACTTGCA\n",
      "TAGAAAATTTTCTTCCACAGCA\n",
      "GTAGGTGATCTAGGCAATGGGA\n",
      "ATCAGTGGTTCCCACCACAGGG\n",
      "TCATTGAGTCTCTACTGCTGAG\n",
      "TACTATATTCTAGACTGCTGCT\n",
      "CCTATTTACTTTCACATCTGCA\n",
      "GCCTATTTTGCTTACTGCTGCA\n",
      "ACATTTCACTTCAGCCACTGAG\n",
      "CAAGTTTTTGTCTCCAGCAGAG\n",
      "CCTGGAAATGTCAACAATGGTT\n",
      "GGCACGATCTTGGCTAACTGCA\n",
      "GGAAGAAATCATAATAACGGAG\n",
      "GCCAAGTTTGTGGTCATTTGTG\n",
      "AAAATGGTCTTGCACAACAGGG\n",
      "ATCATATTAACTAACTTCTGAA\n",
      "CTCCCAAATCTAGCCTATTGCT\n",
      "ACCTTCTTCTTTTTCAATAGCA\n",
      "TCCGGAGGCTTCTCCCACAGCT\n",
      "GAAATCTTTGTAAGGAACTGGA\n",
      "CATCCTTGTTCTATCAACACCT\n",
      "GCTTTTGAAGACGACAACAGGA\n",
      "ACCCTGGACTGCCACCGCTGCT\n",
      "TCCTGCTGCCTCAACCTCTGAA\n",
      "TAAGTGAGCTTCAACAGTAGCA\n",
      "TGGACAGATTGCCTCCTCAGAG\n",
      "CATTTGAACTTGGAAGGCGGAG\n",
      "CTGCTGTGTCAACACCACAGAG\n",
      "TCTTTAGCATTACAGAATAGCT\n",
      "AGATAAGACTTAGACAGTGGAG\n",
      "CCAAGGTATTGGGACCACTGGG\n",
      "TTCCTGTTCTCCCACTTCAGAG\n",
      "CTACAATTTCCTAGCTGTGGGT\n",
      "CAAAGGTTCTTTCTCAACTGAC\n",
      "ACCGCAGAATCCCACGTCTGCA\n",
      "TCCAGGCTTGTCCACAGTTGTA\n",
      "GGCTGTCACTGCCACCACTGCC\n",
      "GCTTTCTGCTGTTTGGACTGCG\n",
      "CAGCAGAATTTCTGTGACTGAG\n",
      "GGCTTTGGTCCTGGATCCTGAG\n",
      "CGCTTGAACCCGGACAGCGGAG\n",
      "GTCTGGTTTGTTCACTGCTGAA\n",
      "GGTAAGTTTTCTGAACACTGAT\n",
      "TTCCGGAGTCTACACATCGGCG\n",
      "CCCAAAGATAGACACAACAGCC\n",
      "AATTACAGTTTGAGTAACTGCT\n",
      "TGTCCTTGCCGCATCAACTGGG\n",
      "CCTTCTGATGGGGGCGACAGAA\n",
      "CTGCTTTGCTGAGACCTCAGAG\n",
      "TCCCACTGCTTACAACATTGGC\n",
      "ACAGGGCATGTGAACTACTGGG\n",
      "AAAACTGGCTTACACAAGTGAT\n",
      "CTGTTCGTTTCACTCCACTGAC\n",
      "CGCACGATCTCTGCTCACTGCA\n",
      "CGTTTACCCTTGGATTATGGAG\n",
      "CTTAAAGAGCTTTCACATTCAG\n",
      "CCGCCCTGCTTCCGCCATTGTG\n",
      "GGGGGTGGTTTGGACCGCAGTG\n",
      "CCTAGGGGTTTCCCCACCTGTG\n",
      "ATGTCCCTCTTTGACTTTTGTA\n",
      "AGCCATGGTTTAGAGAACAGAG\n",
      "GTTCTATATCTTGACTGTGGTG\n",
      "ACCCAGAGCCTAGACAAGAGTT\n",
      "GGCGCCTGCTCTAGTCACTGAG\n",
      "CTGCATGATCTTTTCAGTTCCA\n",
      "TTTCAATATTTTGACAACTGAT\n",
      "CACTTGAACTCGGAGGGCGGAG\n",
      "GGGCGTGGTTTAAGCAATGGCA\n",
      "TTTTTTGTTTTGCACATTAGAT\n",
      "GTCTTGGCATTTGATAACTGAG\n",
      "ATATTAAACTTAAAACACGGAG\n",
      "ACCAGGAATCCTAATCACAGTG\n",
      "GCTGAGGTACTAGGTGACTGAG\n",
      "CTTAATATTGTAAACTGCTGCT\n",
      "CAGGCCTATTCTAACCACTGAT\n",
      "GACCACGTGTTTGGCTACAGAG\n",
      "AGGTGAAAACCTGCCCTCAGAG\n",
      "CAGGGAGGCCGAGACCACAGCG\n",
      "ATCTATGGTTCACACTTCCGTG\n",
      "TAAAAGATCGTATGTAACAGCT\n",
      "TTAAGCAGCTCTTTCAACTGAC\n",
      "TGATTTTTCTTCTATATTTGAA\n",
      "GGCGCGATCTTGGCTCACTGCA\n",
      "AAGACCAGCTTTGTCATTTGCA\n",
      "GGCACCATCTTGGCTCACTGCA\n",
      "ATTTTTAAATTTGACAACGGAA\n",
      "CTCACCTTCTTCAACCCCTGCG\n",
      "TCTGTAGTTTACAACAATTGAA\n",
      "ATTGGTGGGCTAAACCACAGGC\n",
      "CCTCACTGCTTCTGCCTCTGCC\n",
      "CTCCTCAGTTTTTAGAATAGTA\n",
      "CAGCCTAGCTGGGACCACTGAG\n",
      "TCCATCAGCTCCCACAACTGAG\n",
      "CTGTTGTCTCTAGACCACAGCA\n",
      "CTGCTGGATCTCCCCAGCAGAG\n",
      "GGTATGTTTTCTCTCCTCTGGA\n",
      "CACTCTATCTTTCATGACAGAT\n",
      "AGGGACGATTTGCTCTTCTGCT\n",
      "TCTTTGAGTCTTCACACCTGAG\n",
      "TGTGCTTTTGCCCACAACTGGG\n",
      "GACTGATTTGTCTGGCACTGAG\n",
      "TCCCAGAGCTTCTCCTGTAGGG\n",
      "TGATTTACTAAACACAGCAGAT\n",
      "TAGTAGGCATTTTATGATAGAA\n",
      "CTCATGCCTTTCCACAATTGAA\n",
      "ACCATTACCTTTGCCAACTGTG\n",
      "TTTCAGGATTTTAACATTTGAG\n",
      "TGCCCCTGACTCCACGTCAGGG\n",
      "AGTTTGATCTCAGACTGCTGCA\n",
      "GTTCTGTTTTATTGCTACTGAG\n",
      "GGCGCAGTCTTGGCTCACTGCA\n",
      "ACTCTGTGTTGTGCCTGCAGCA\n",
      "CATTTTTATTTTCCCAAAAGAG\n",
      "TGCCCTGATCACAACCTTTGTG\n",
      "CAGATACTCTTCAACCTCTGCA\n",
      "TAGAGGGCTTTGGACGACAGAC\n",
      "GTTCCTGGCTTTAAGAACAGTA\n",
      "TGTTGGGATCTCAGCTACTGCA\n",
      "GGCTGTCACTGCCACCACTGCT\n",
      "CAGCAGGGGTAGAACCACTGCT\n",
      "CCATGTTGCTCCTGCAGCTGCA\n",
      "AGTTGACCCTTCAACAACACAG\n",
      "CAGGTGGGTCCCAGTGGCAGAG\n",
      "CAAGCCCCCTTCCACCACTGCC\n",
      "ACAGGGTTTCTCAACCTTGGAG\n",
      "AGTGTCAGCTTGAACTGCAGCC\n",
      "CATTAGAATCTGGGAGGCAGAG\n",
      "CTCCAGAACTGTGAGAAGAGAA\n",
      "TCTCTTGGCTTCCTCCTCCGCT\n",
      "GGCATAATCTTAGATCACTGCA\n",
      "CTGAAAAGTTCAGGCGGCTGCA\n",
      "TGCTCGAATCCGGGCAACGGAG\n",
      "ACCAGGCATCCTCACCACTGCA\n",
      "TACTGGTGTGTCTCCCCTTGAG\n",
      "AAAAATTGTTTCTCCCACTGTG\n",
      "TGAGCTAACTTCACCCACAGCT\n",
      "AAGAGCTACTTAGACTGCACAG\n",
      "TGTGTGCGCCTAGACACGGGAG\n",
      "GGCAGAATCTTGGCTCACTGCA\n",
      "TGATATGATTCAAGTAACTGCC\n",
      "TAATGCAGTGTCAGCAGCAGCA\n",
      "ACATGGTGTTCCCATGGCTGCA\n",
      "TGTGTGCTCTCCAACAGGAGAG\n",
      "ATCAGGGACTCACTCAACAGAG\n",
      "TGCTACTGCCTCTCCTGCTGCT\n",
      "ATATCTTGTCTACACAGTGGAG\n",
      "CTCAACTGCTTCCACCACTTCA\n",
      "TAAATTCTCTTCTCTAACTGCA\n",
      "TAGTTGAAACAATGCAACAGCT\n",
      "TAGCACTGGCTGCACCACTGCC\n",
      "ATAAATGATTCCACTTACAGAG\n",
      "TAAGGAGATATAGAACACGGAG\n",
      "GGCACAATCTTGGCTCACTGCA\n",
      "GATAGGCAATTTAATCACAGTA\n",
      "AAAGAGATACTTGATAGCTGCT\n",
      "GGCGTGATCTCGGCCCACAGCA\n",
      "ATTTTGTTTGTCAGCTGATGGA\n",
      "GCTGTAATCTTCAGCATCAGAC\n",
      "GATCTCGTCTTCTCCTGTAGAG\n",
      "AATATGTTTGTTAACAGGAGAC\n",
      "GCCTGTGGTCCTAGCTACTGAG\n",
      "CATCATGTTTTCCTCCTTGGAG\n",
      "AATGAGTCTTTATATTTCTGAG\n",
      "ATGACATCTTTCTCCAATTGAG\n",
      "AAACAGGATTTGCACCCCGGGG\n",
      "TATCTGGATAGAAACCACAGCA\n",
      "TGCTTGAATCCAGGAGGCGGAG\n",
      "CACCTTGGCTCAGACAATAGCA\n",
      "AGCCTCTGCTTAGACACCTGCA\n",
      "CCTAACTGATCAGACTACTGCC\n",
      "TTTAGGTGTTTCAAAGGCTGAG\n",
      "ATTAGATGCTTTAAGAATAGAA\n",
      "TGTTTGGGCTTTAACATCAGAC\n",
      "TCTTGCAGCTTCCACCACTGCT\n",
      "TGCTTGAACTTGGGCAGCAGAG\n",
      "GCCTGTTGCTTCTGTAGCAGCT\n",
      "CACTTGGATCCTAAAGGCGGAG\n",
      "GGTGCAATCTTGGCTCACTGCA\n",
      "CTTGATTTCTTCTCCCTCAGCA\n",
      "AACTACAGCTTTCACCACAGCT\n",
      "AATAAGTGTTTGGATAACAGAC\n",
      "GGCTTCATCTTCAAATGCAGTG\n",
      "CACCACATCTAAAACAACTGCC\n",
      "CTGTTATGGCTGTACTACTGCA\n",
      "CCCTTAATTCCTGACAGCTGCG\n",
      "AGTGAGATCTTGGCTCACTGCA\n",
      "GGCATGATCTTGGCTCACTGCA\n",
      "CTTCTGAATCTTCACATCTGCT\n",
      "GCCTCAGGTCTGAACCACTGAG\n",
      "TTGCCAACACTACTCCACTGAC\n",
      "TCTTTGAGTTTAGACCACTGCT\n",
      "GCTTATTGGTTTCACCTGTGAG\n",
      "TCCACTCGTTCATCCCACAGCA\n",
      "CTCTCTAATCTCCCCTGCTGAG\n",
      "GTGTAGTTTTTCTCCATAAGAA\n",
      "TCTACTGACTCTGCCAACTGAT\n",
      "AGTGTTGGTCCCAATGACAGAG\n",
      "CCCGGGAAGTTGAATCACGGAG\n",
      "GTTTTTGATCCTAGCCACTGAG\n",
      "GAAACAGCTCCCGCCTACTGAG\n",
      "GAAAGGAATTATTACAACTGAT\n",
      "CACATGGCTGTCCACAGCTGCA\n",
      "TCTCTTGCCTTTCATCATTGAG\n",
      "TGCTTGAATCTGGGAGACAGAG\n",
      "AACAGAAGCACTTGCAATAGCG\n",
      "GCCACCCATTCTAACATTGGCA\n",
      "AATTGTTCTTTTTGCCACAGAG\n",
      "AGCGGGTGGCTGCACCTGAGAG\n",
      "CCACTAAAATTAGAGAACAGAG\n",
      "AGAGGGTTGTTCCACCACTGCT\n",
      "ATTTTTGGTCTATGCAACTGTA\n",
      "TTTGGAGCACCTGACTCCAGAG\n",
      "GGATGGTATTCATGCCATTGAG\n",
      "AAAAATGGGATCGATAACAGAG\n",
      "TACCTTGAGTTTGACAATTCTG\n",
      "TTTTCTCCTCCCAATAATAGTG\n",
      "TATTCGATTTTCCACAGTAGGC\n",
      "TGGTGGCATTTCAACCTCTGTG\n",
      "TGTGGGGTTGGGCACCATTGCT\n",
      "AAGGACATTTTAGACAAAGGGA\n",
      "AATAGCTGTCTGAACAACAGCC\n",
      "GCTGTTGTGTTAAACCACTGTG\n",
      "TGTCCTAAATTTGGCAACTGAG\n",
      "CCATCTGGCTCATACCACTGAT\n",
      "GGCTATGGGTCAGACAGCTGTG\n",
      "TGACTTATCTCTCACAACTGAA\n",
      "CTGTTCCTCTTTTTCAACAGGC\n",
      "AGAGGTGACTTTGACTTCCGAG\n",
      "CCTAGTGCTCCTAACTACTGAG\n",
      "CACTGGGGCTTCTTCCTCTGCC\n",
      "TTACAGAATATAAACAACAGTA\n",
      "CATCATATATTTCACCATGGAG\n",
      "TCCTCTGGCTTCTAGTACAGAC\n",
      "AACAGTGGTCTTAACCTTTAAG\n",
      "CGAGGTGCCTTCCCCTGCAGTG\n",
      "CCGGGCTGCCTGGACATCAGCG\n",
      "GTATGGAGATTTTGTAACTGCA\n",
      "TGTCTCTTAGGATACCACTGCC\n",
      "TGGAGTTTCTTTCACCACTGCC\n",
      "GTTAAATGCTTCACCTCTAGGA\n",
      "CACTCCAGCCTGGACAACAGAG\n",
      "CCAACAAGCTCTAGTCACAGGG\n",
      "ATTTGTGAATCTAACATTTGGG\n",
      "CCTCTGTGTCCCATCATTTGAG\n",
      "CACCACTGCTTCCACATTAGCG\n",
      "TCTAATGATTCTCTGAACTGCA\n",
      "CCTCACTGCTTCCTCCACTGCC\n",
      "AATGAGAGCTCGCATCATGGAG\n",
      "TCATGCGTCTTCTCCTTTTGAG\n",
      "CTTCAGTTTGTAAAACACTGCA\n",
      "CTTAATGACTTTGGCAACAGAG\n",
      "AGAAGCCCCTTCAACTCCTGAG\n",
      "GCTGGGTTTGCTGTCAGGTGCA\n",
      "GGTCTCAGTTTGGACAATGGGG\n",
      "AGCTATGGAGCTCAGAATAGAG\n",
      "ATTTAGCATTTCAACTACTGCT\n",
      "CCCTGCACTTTACTCTACTGAG\n",
      "AGGGTGTGTCCTGGCCTCAGAG\n",
      "AAGCAGGTTTTAGACAATGGCA\n",
      "ATTGTCTGTTTATACGCCTGTG\n",
      "TGGGAAAACTTGAATCACGGAG\n",
      "GAGCTCGTTTTCTTCATCAGAC\n",
      "CCTCCTCACTCACACCACTGCT\n",
      "TAAAGTATTCTCAACTATTGTG\n",
      "CTTCGAGCTCTCAACAGCAGTG\n",
      "AGTCTTAGCTTACAGACTAGAG\n",
      "AGGTACAGCTGCAATTGTTGAA\n",
      "GGCTTGAATCTAGGAAGCCGAG\n",
      "GATATCATTTCACACTACTGTG\n",
      "GAATGGAGCTTGCGGGACTGGA\n",
      "TAACCTTGTTCCCTCAGCAGCA\n",
      "TACTATGATTAGGACAACTGAG\n",
      "GTTTGCAGTTTTGACAGCAGAT\n",
      "GATGGTGGCTTGGACCTGAGTG\n",
      "TGGAGTGTCTTATACTGCAGAT\n",
      "CACTTGAATCCGGGAGGCAGAG\n",
      "TCACAGTTATTAAGCAATAGAG\n",
      "CTACCATTCTTCAGTAACTGCT\n",
      "AGGCAAGGTAGCAACAGCTGGA\n",
      "TGCCTTAGCTTCAGTAGCTGAG\n",
      "ACTTTGTATTCTCACTTCAGAG\n",
      "TGCAGAGGCCCAAACAGCAGAA\n",
      "CTGCCATTTTCAAGGAACAGAA\n",
      "AGAGACAGTTTTGACAACAGTG\n",
      "AGTGGTGGTAGTGACAGCTGCA\n",
      "GTTTATTGCTTACATAATAGGG\n",
      "GCAATGTTTTTCTACCACTGAG\n",
      "TCCTTTGGTCACCACCACTGGG\n",
      "GTGCCAGTTTCCTACTGCTGCT\n",
      "TGCTTGAATTCGGGCAGCAGAG\n",
      "TTATGTGATCCTGGCCTTAGAG\n",
      "CACCTGAACCTAGGAGACAGAG\n",
      "TCTCCTGGCTTCCCCAGCTGCC\n",
      "AGATTTAATTTAAGCAATAGGG\n",
      "GTGTGGGAATTTGACTACTGTG\n",
      "GGACTCAGTTTCCTCATCAGAC\n",
      "GAAATATTTCATGAGAACTGTA\n",
      "TTTTCATGATTCCAACCCAGAG\n",
      "CTTCATACCACCTCCAACTGCT\n",
      "CCAGGGTCATTCCACACTGGCT\n",
      "GTTTTCAGTTTATACACCTGAC\n",
      "AGTGACAGCTGCGGTAGCTGCG\n",
      "AAATAGAGTTTGGACTACAGAA\n",
      "GTTTAATGTTTTAACAACAGCA\n",
      "GCAGGTTATTTCGACAGTCGAA\n",
      "GGCGTGATCTTGGCTCACTGCA\n",
      "GCCCTGAAATTTTACAGTAGCA\n",
      "CTAAAACTCTTGTACAACCGAA\n",
      "TGGACCAGCTTCCCCAGCAGAG\n",
      "AGAAATGCCTCTGATGACAGAG\n",
      "CCTTCTGGCTTCATCAGCTGCC\n",
      "TTTGGTAATTTTGACAATAGAA\n",
      "TTTCATTTTTATCACCACTGTC\n",
      "ACTGGTGATCTTGACAAGAGCA\n",
      "AGAGCTGCTCCCTGGGTGGGAG\n",
      "TATAGAGGGTTTAACTTGTGAG\n",
      "ATGTACCCATTTGACAACTGAG\n",
      "GCAGGCTGCCTCTCCCTCTGAG\n",
      "TGGCACGATCTCGGCCACTGCA\n",
      "GCTGAATTTGGATACTTCAGGT\n",
      "AACTGCAGTTCTGACTGCGGCT\n",
      "GGGTGTCACTTCACCAGCTGAA\n",
      "ACTCCAAGCTTTTGTCCCTGCT\n",
      "ATTCAGTTTCCTAACTCCAGCA\n",
      "TTGATAAATCATAATAGCAGAG\n",
      "CAAATGGTTTCTTAAGACAGAG\n",
      "TTGACCGTCTTGTCCTCTTGGG\n",
      "AGACACAATCGCAAACACTGTA\n",
      "TGCTGTTGCTGTTGTAGCTGCT\n",
      "CCAAGGGCATTCAGCTTATGAG\n",
      "GGTTGGTTTTGCTATATCAGAG\n",
      "CTACTGAGTGTTAACATTTGCA\n",
      "GAATGGGATACCTACAGCAGGG\n",
      "GGGTCTGCTTTCGAGACTAGCA\n",
      "CATTAAGAATTACATAACAGCA\n",
      "CACTTGAATCCGGGGGACAGAG\n",
      "CTCTACCTCTTCCACCTCTGCC\n",
      "CTCTAGTAGCCTTACAGCTGAG\n",
      "CTTCTGTGCTGCACCAGCTGAG\n",
      "GCCTGTAATCCCAGCTACTGAG\n",
      "ATTCCAAGCCTCAACAAAAGCG\n",
      "ACCCAGGGCCTCCACCTTGGAA\n",
      "ATCAGGCACCTTTGACCAGGAG\n",
      "ATCTTTTGTTCTCACAATGGTG\n",
      "TTGTTGGATTTACAACACTGAA\n",
      "GGCAGTATTGTCAGCTACAGGC\n",
      "CTTATCATTGATTACTACTGCT\n",
      "GTGCATGTCTTCCACTGTCGAG\n",
      "CAGAAAAAATCATACAACTGAT\n",
      "AGAAGCTGCTTCTCCCATGGAG\n",
      "GAGGATCGCTTGAACCTGGGAG\n",
      "CAATATGAATGTAACAATAGCT\n",
      "CTCTTTGCTTTATGCCACTGGC\n",
      "CCGACCCGCTTTCCCGACGGCG\n",
      "CCTGGCAGCCATCACTGCTGCC\n",
      "ACAAATCTTTTCACCACCTGCC\n",
      "ATAGCAGTTTTCAATCACAGAA\n",
      "TAAACTTAATTTAACACCAGGG\n",
      "TTACTCAGCTCTCACAACAGCT\n",
      "TGACTTTTTGTCCAGATGAGAG\n",
      "ACTGGTGACTTTAACTACAGCT\n",
      "AGGATAGCCTGTCACCTTAGAG\n",
      "GGCATCGTTAAAAACAACAGCA\n",
      "ATATTTTTCTTCTACCTCTGCC\n",
      "AGCATGTGTGCTGGCTCCAGGG\n",
      "AGTTGTTGTTTTGGTTGCTGCA\n",
      "GCCTGTAATCCCAGCTACTGAG\n",
      "AATTGTGGTTGTATCAGCTGAG\n",
      "GTGTGCTGCTTCCAGTGCTGCT\n",
      "TCTGAGGCTTTCCACACCAGAA\n",
      "CAGCTTCTTTCATGCCACAGGG\n",
      "TCACTGTTACCATCCAACTGAG\n",
      "CTCAGCGGTCCCTACGATGGAG\n",
      "CGGGGGATTGTTGACGCCTGCG\n",
      "AAGTGATCATCCTACCACAGCC\n",
      "GACTGGGACTTACACCATTGGG\n",
      "CAGGTGCTGTTAGGTCAATGAG\n",
      "AAGAATCGCTTGAACCTCGGAG\n",
      "GACAGAAATCTCCACCAAGGAA\n",
      "TTCCCTGTACTACTCCACTGAA\n",
      "AAGAAAGGACTTCACAAGGGAG\n",
      "GGCACAATCTTGGCTCACTGCA\n",
      "GGTTGGTTTTGCGGTCTCAGGG\n",
      "ATAATCAGCTTTCTATACGGCC\n",
      "AAGCAATTCTTCTGCCTCAGCC\n",
      "CCCAACTTTTTTGGCACCAGGG\n",
      "ACACCTTTTGCATTCAACTGAG\n",
      "TGAAACAATCCTAACCCTAGCT\n",
      "ACTGCATATTTTGACCACAGAG\n",
      "AACATCAGCTTACAGAACAGGA\n",
      "CAGTAAGTTTGTTACAGTTGAG\n",
      "GGGTGGTTTGTGTCCATCAGAA\n",
      "ACATAGTATTTAGACTACTGAA\n",
      "GAACTGTATCTCAACAGTTGCC\n",
      "GGGGCGATCTTGGTCCACTGCA\n",
      "TGAACCCGCTTGAACCTTGGAG\n",
      "AAGCTGCCTTCCTCCCACTGCA\n",
      "GTAAGAATCTCTAACAATAGAG\n",
      "AGTGTGGATTTCCACAGGTGAG\n",
      "GCAGGGGATCTGGAGCACAGAT\n",
      "CCCTCATTACTAGAATTCTGGG\n",
      "AGCAGAACTCCAAACAGCAGGT\n",
      "TGCTATTGCTTTTGCTGCTGAT\n",
      "TCCTTGTGTTCTGGCATTAGAT\n",
      "AGGTTGTGTCTTGACAACTGTG\n",
      "AAACCCACCTTGTTCATCTGCA\n",
      "GGTTGGTTTGTCAACAGGACGG\n",
      "TGTGCAGACCTTTACCACAGCT\n",
      "AAATTATACTCTTTCCACTGAG\n",
      "ATGTGTGATACTAACTTCAGAG\n",
      "TGACAGTTCTTAGAGGACAGTG\n",
      "TGGCCCGATCTCGATCACTGCA\n",
      "CCATTTGGTTTTGAGGATAGTG\n",
      "ATCTGTTTTGTTCACTTCTGTA\n",
      "ATCCAAAGTTAATGCAACTGCA\n",
      "GGCGTGATCTTGGCTCACTGCA\n",
      "GGGGGGACCCCTCACAACCGCC\n",
      "CTTGGCTACTGGCACCACAGAG\n",
      "CAACTTGATCTATAGAGTTGAG\n",
      "CGCCACTGATCACCCAACTGAT\n",
      "GGCACAAGCTTGGCTCACTGCA\n",
      "TTATGCAGTTCTGTCAGCTGAG\n",
      "TAATTTTATTTTTTCAGACGGG\n",
      "AACTCAAGCCTTGACCTCTGTG\n",
      "GAGAATTGCTTGAACCTTGGAG\n",
      "ATAAAGAAATTCTCCAATTGGT\n",
      "CTGTGGGTTACACACCACGGGA\n",
      "TTAGGTGATCCACACAGATGTA\n",
      "AAGAAATACTTGTTCAACAGTG\n",
      "ATTGTTCTCTTAGTCATCAGAT\n",
      "AGGGAAATCTTTGACCACAGAA\n",
      "AGTGGGTGTCCCCACCACAGAG\n",
      "TGTAATTGCTTCTCCTGGGGCA\n",
      "TGTTGACTTCTCTACATCTGGG\n",
      "TTTACCTTCTTTGACTGCAGAT\n",
      "TCTATGAACTTCATCCACGGTG\n",
      "ATCCAGTCATTGGCCACCAGCC\n",
      "GACAGGAATTCTTTCTTTGGAG\n",
      "AGTGACTCCCCAGACCACAGAA\n",
      "CAGCCCCGTCACCACCGCAGCA\n",
      "ATGTGCTTCCTTAACTAGCGCA\n",
      "TGGTCTCTCTTGAGCCATTGGA\n",
      "AAATTGAATTTAATCAACTGAA\n",
      "TTGGGATGTTCTTTCTCCAGAT\n",
      "TGTGATGATCCTTGAACTGGAT\n",
      "TTGGACGATTTGGAAGCTGGCG\n",
      "AAAACAGATCTCTACCTCTGAG\n",
      "TTCCTTAGTTTTAAGAGATGAG\n",
      "GGCATGGTGGCTCACAGCTGTA\n",
      "AATGGGCCTTTGAACATCAGCA\n",
      "TGTCTGTGTCCAAGTTGCTGCG\n",
      "TAGTGGAATCTTGGTCACTGCA\n",
      "AGTGTGGTGTTGCACATCTGCA\n",
      "GGTGGTGGTTCATAGAACAGCC\n",
      "ATGCATGGCTTCCTCTACTGTA\n",
      "CCCAGGAATCTATGCCACAGAA\n",
      "TGTGGTCTCATCAACAACAGAG\n",
      "AGGAAGTTTTCTGACAACTGTG\n",
      "CACACAAGCTTTAACCTCAGAG\n",
      "GTCTGGCTTGTGAGCAGCAGCA\n",
      "TCCAGGGATGTCCGCAGCTGCA\n",
      "AAGGATAATGCCAACCGCAGAA\n",
      "GGTGTGATCTCGGCTCACTGCA\n",
      "TATTATTTTTTAAGAGATAGGG\n",
      "AATGAGAGTTTACATGACAGTG\n",
      "TGTATTGATTGCAGTAACAGTT\n",
      "TGCTTGAATCCGGACAGCAGAG\n",
      "CACTTGGATTCGGGCGGTGGAG\n",
      "TTCCCATGCTTACACCTTTGCA\n",
      "ACTCAGCATATTCCCAGCTGTG\n",
      "GTTGGAATCTTGGTTCACTGCA\n",
      "CGTGTGGTTGTGCACACCTGTA\n",
      "GTTTATAGTTCAGGAAACTGAG\n",
      "CCATTACATTTCTCCTGCTGCT\n",
      "CCTGATGGTTTTTCAGATAGAG\n",
      "TCCTGTGGCCACCACCACTGGG\n",
      "TATGTCCTTTCACACCTCTGCA\n",
      "TCCTCCTGCCTCAACCTCTGAA\n",
      "GAAGGAGTCTTTGACCGTAGCC\n",
      "GTCTCTGTGCTTTACAGTAGTG\n",
      "ACACCCAGTCTCAGCAGCTGGG\n",
      "AGCTTGGGTTTAAACCTTAGAA\n",
      "AGGTGGTTCCCTGATCATAGAG\n",
      "CACCTGAATCCTGGAGACAGAG\n",
      "CAGTAAAGTTCAGACTGAGGTG\n",
      "CCTGTTGCTTCTAACCACCGAG\n",
      "GTGTATTAGTTCAGCATTTGAG\n",
      "AAATAAAGCCGAGACGACGGCG\n",
      "AGAGAAGGCTTAGACACCAGTT\n",
      "AAGGGGTTTGCAGATGATTGTG\n",
      "TTTAAAGTAGTGTATAATTGGG\n",
      "ATATTTATCTTATTCATCTGAG\n",
      "GGGACACATTTAAACCACGGCA\n",
      "GCCCATGCTCTTGACCACTGCC\n",
      "GAATTGTATGTGCACAGCGGCA\n",
      "GCCAAGAATAAAAACAACTGAG\n",
      "ATCTACAGTTCTAACAGTTGAC\n",
      "AATGGGTTTTCTTATAACTGAG\n",
      "TCACGAGATACATTCAACAGAC\n",
      "ATGTGGTGCTGCCTTCACTGAT\n",
      "GGCAGTTGCTTCTACAATATGG\n",
      "CGCTTGAACCTGGGCGGCAGAG\n",
      "ATCCCTGGCCTCTACACACGAG\n",
      "GTTTATTTTTATGACTCTAGCA\n",
      "TTTAGGCTTGTGGGCAATGGGG\n",
      "TTCGGCAGCTCACAGTACAGCA\n",
      "ATCAGAATTTCAGACAACAGGT\n",
      "TAGGGATGCTTAAACTGCAGCC\n",
      "GGCGTGATCTTGGCTCACTGCA\n",
      "AGAAAGTTTTCAGTCTACTGAG\n",
      "TCAGGTGATCCACCCAACTGGG\n",
      "AGGGCACATTTAGACCATAGCA\n",
      "AGTGCAGAATCAAATCACAGCG\n",
      "TAGGGCAGTTCAGACGCTAGGA\n",
      "TATATGTATCTTTACAGGTGAA\n",
      "CTTGGCTGCTCCCACTGCAGTA\n",
      "ATTTTGACATACTACCATTGTG\n",
      "GACTTGTGTCTCAAGAACTGAG\n",
      "GGTGTCAGCTTTCTCAGTGGCC\n",
      "TGGCGCGATCTCAATCACTGCA\n",
      "GGATGGAGCTCTGAGGACTGCA\n",
      "AGGACCAACTCATCCCTCTCAG\n",
      "CCCAGAGATTCGGATGTTTGAG\n",
      "ACCACTTGTCACCTCCACAGCT\n",
      "ATATATGCACCTAACACTGGAG\n",
      "CTTTTCAGTAGTCCCAGCTGGG\n",
      "ACCCAGAACATTCCCAGCTGCG\n",
      "CACTTGAGAAGGAACCACAGAG\n",
      "AAGTTCTTCTTCTCCATCTGAG\n",
      "AATGCAGTGTGGCACAACAGAG\n",
      "GCCATAATATTTCACAACAGAA\n",
      "TTTCATTTCTTCTTCGTCGGGG\n",
      "AGAGGGTTTTCCCACCACTGCT\n",
      "TCTTCAATCTTCAGCAGCAGCA\n",
      "CAGCTGTCTTTGTACATCAGCA\n",
      "TAAAAGCCTCCTGATCACTGAA\n",
      "GAAGAATGTCTACTCCACAGCC\n"
     ]
    }
   ],
   "source": [
    "for seq in predictions[predictions['targets'] == 1]['seq']:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTTAGAGTCCCAACTACAGAG\n",
      "TGGTTACAACCTAACTACTGAG\n",
      "TTTGTCAACTTCAGCAACTGGG\n",
      "AATAATTTTGTAAACTGTAGAG\n",
      "TAGTAGTAGTAGTGCCACAGTG\n",
      "TGACCTGGTTTATTCAACAGCA\n",
      "TATCTGGATAGAAACCACAGCA\n",
      "TGTTTGGGCTTTAACATCAGAC\n",
      "TCACAGTGTTTAGAACATTGTA\n",
      "AACTGAAGCTTCTACAACTGGA\n",
      "CTCTTGAGTCTTTACACTTGAG\n",
      "TTTCAGGATCTTAATCTCTGAG\n",
      "TTTGTAGAGTTAGTCCTTAGAG\n",
      "AGGATAGCCTGTCACCTTAGAG\n",
      "TGTACCTGCTCCTCCAACAGCA\n",
      "TAATTTTTTGTTGGTGGTAGCC\n",
      "AAGTCAAGCTTCTCCACCTGGT\n",
      "TCATTGAGGCTCTCCTGCTGAG\n",
      "TTGTATGCACTGAGCTACTGTA\n",
      "GGGTGGTTTGTGTCCATCAGAA\n",
      "GTGGGTTGTGTATACATCTGCT\n",
      "TTAACTAGTTGCTCCAATTGCA\n",
      "GATGGTGATCCACGCAACAGAC\n",
      "TGTGTGTTTCTTTACCATTGAA\n",
      "GCTCTGAGTCTATACAACCGAG\n",
      "CAGGAGGTTTTCAGCACCAGTG\n",
      "ACAAAGGCTTCTGACATCAGAA\n",
      "AGATGGACTCCTGACAAGGGAA\n",
      "AGAATGGGTTTGGACCAAAGGA\n",
      "AGAAGCTGCTTCTCCCATGGAG\n",
      "ATAAATTACTTCAACACCAGGA\n",
      "TACATGGTGGCTGATAACTGAG\n",
      "CACCACCCATATGGCAACGGAG\n",
      "CAGTCAATTTCCAACTGCAGAC\n",
      "ATTTTATATATGCACAACTGTG\n",
      "CAGTGGTTTGACCACAACAGTG\n",
      "CGTCTCAGCTTCTACTGCGGAA\n",
      "AGTGTGGATTTCCACAGGTGAG\n",
      "TGTATAGGTTTAGACAATAGAG\n",
      "AGTAACTGCTTGGATTACTGCC\n",
      "CAACTTGATCTATAGAGTTGAG\n",
      "GAGGATGAACCTAGCAGCAGCC\n",
      "GCCTCCTGCTTGCTCAGCTGAG\n",
      "TGGTTACAACCTAACTACTGAG\n",
      "GGCGTGATCTTGGCTCACTGCA\n",
      "GTTCTGTATCTTGACTATTGTG\n",
      "CATGGAAATCTACCCACTAGAG\n",
      "ATGTTAAACTTTCTCACTAGAG\n",
      "AGGTGCTTTGTCCCCTGCTGAC\n",
      "CTGAAGTTTTTGAACATCTGCT\n",
      "GTCTGTTTTGTTTGCTGCAGAG\n",
      "GAGAATTGCTTCAACTGCAGAG\n",
      "TGACAAAATTTAAAAGACAGAG\n",
      "CTTTATGGTTTTTACAACTGCT\n",
      "AGTGGGGCATTAAACAATAGAG\n",
      "CAGGCCAGCCTATACCATTGAG\n",
      "CATCATGTTTTCCTCCTTGGAG\n",
      "GAGGGGTAACTAGGCAACTGAG\n",
      "AGCCCCTGCTTGTTCTGCTGGA\n",
      "TTGAGATGCTTGTAGGACAGGG\n",
      "AGCAGCGATTTGGACGGCTGCA\n",
      "ATGTAGTGTCCCTTCCACTGAT\n",
      "TGCAGAGATCTTGGCAATAGGA\n",
      "ACCAAAGGTTTTGGCAAGTGCA\n",
      "TATTATTTTTTAAGAGATAGGG\n",
      "ATCAAAATTTTTAACAATAGCT\n",
      "AAAAATTGTTTCTCCCACTGTG\n",
      "GACCTGAGCTTCCACTTTTGGG\n",
      "AGCACGGGCTCTGACTTCAGGG\n",
      "CTCATGCCTTTCCACAATTGAA\n",
      "ATTTTGTATTTGAGTAACTGAG\n",
      "ATTGTCTGTTTATACGCCTGTG\n",
      "ATTTGCTGCTTTTACAGCAGGT\n",
      "TCTTAGAGTTTAGACAATTGAG\n",
      "TAAAGCAATTCAGATAATTGTG\n",
      "AGAAAGTTTGTTTCCTACAGAG\n",
      "GGCTCGATCTCCGGTCACTGCA\n",
      "TTAATGTGTCCTGACCCTGGAA\n",
      "AGCAAATATTCTATCATCTGAA\n",
      "CAACAGTTTGTGTGTAACAGGC\n",
      "TTATGTGATCCTGGCCTTAGAG\n",
      "TATGCATATTCTGACCACTGCT\n",
      "AGGGAAATCTTTGACCACAGAA\n",
      "TTCTTTGGCTTTAGCAGTAGCA\n",
      "ATGTAGTGTCCCTTCCACTGAT\n",
      "TATTGGGATTTCAGCTACAGCT\n",
      "GGAAAACACTGTGACCTCAGGA\n",
      "AGAAAGTTTGTTTCCTACAGAG\n",
      "AACTGAAGCTTCTACAACTGGA\n",
      "TCTTAGAGTTTAGACAATTGAG\n",
      "TTAACTAGTTGCTCCAATTGCA\n",
      "TCACAACCACTCCACCACTGCA\n",
      "ACAGAGATTTTCTCCAATTGTG\n",
      "GGCAAGATCTTGGCCCACTGCA\n",
      "AGGAAGTTTTCTGACAACTGTG\n",
      "AGCCTCTGCTTAGACACCTGCA\n",
      "CAAGGATTTTTGATCAACAGAG\n",
      "GTCCATGAGGAAGACCATAGAG\n",
      "GGGAGCTCTTCCACCCTCAGCA\n",
      "CTTCGAGCTCTCAACAGCAGTG\n",
      "CTTCTGCTTGCTGACAGCTGAG\n",
      "GGGTAGTGTCATAACATCTGCC\n",
      "GCTCTGGGCTTCTCCCACAGAG\n",
      "GAGGATGAACCTAGCAGCAGCC\n",
      "AAATAGAGTTTGGACTACAGAA\n",
      "CCCCGTGATTACTGCAGCAGTG\n",
      "GAAAGAGTCTTCTCCCATAGCC\n",
      "GATGGTGATCCACGCAACAGAC\n",
      "ACAAGAGGAAGCAACTACTGAG\n",
      "ATTTAGAATCTTAGCAACTGCA\n",
      "CAGGCATGCTTGTGCCACAGAC\n",
      "CTTGATTTCTTCTCCCTCAGCA\n",
      "GACCTCGATTCGGATCATGGGG\n",
      "CCCCCTTTTTTATACATCTGAT\n",
      "GTTCTGTATCTTGACTATTGTG\n",
      "TGATGTAAACTACACATCTGAT\n",
      "TTGTGGTTTGATGCCACTAGAG\n",
      "AAAAGAGGTTTACACGTCAGTG\n",
      "GGTATGTTTTCTCTCCTCTGGA\n",
      "ATTTAGCATTTCAACTACTGCT\n",
      "ATTTAGCATTTCAACTACTGCT\n",
      "CGTCTCAGCTTCTACTGCGGAA\n",
      "TGGAAGTTTGTCAAATACAGAC\n",
      "AGATGGACTCCTGACAAGGGAA\n",
      "TACCCTGGCTTCTTCTACAGAG\n",
      "CCCTTCTTCTTCACCCTCTGCC\n",
      "TGTACCTGCTCCTCCAACAGCA\n",
      "CTACCATTCTTCAGTAACTGCT\n",
      "TATTCATATTTACACAATAGCA\n",
      "TTGAGATGCTTGTAGGACAGCG\n",
      "ATAAAAGATTCCATCATTTGGC\n",
      "ATTTTATATATGCACAACTGTG\n",
      "TGAAAGTTTGTACATCACTGAA\n",
      "AGTTGGGATTGTGATAACAGCC\n",
      "CCTCACTGCTTCCTCCACTGCC\n",
      "GGGTGGTTTGTGTCCATCAGAA\n",
      "TGCAGCTGCTCCGACCACAGCT\n",
      "CATCATGTTTTCCTCCTTGGAG\n",
      "TCACAGTGTTTAGAACATTGTA\n",
      "GTTTGGTTTGTTTGCAACGGCA\n",
      "AGCCTCTGCTTAGACACCTGCA\n",
      "GGTTATTTCTTAGACACCTGCG\n",
      "GCCTGTTGCTTCTGTAGCAGCT\n",
      "GGGCAGGAACTCTCCAGGTGCG\n",
      "GCAGGATTCCTAAATCACAGCC\n",
      "TTCTTTGGCTTTAGCAGTAGCA\n",
      "GCCTGTGGTCCTAGCTACTGAG\n",
      "AGAATGGGTTTGGACCAAAGGA\n",
      "AGTCAAAAATCTGACAACGGTA\n",
      "TTTAAACATTTTAACATCTGCA\n",
      "GATCACAGTACTCACTTCAGAG\n",
      "CCCCCTTTTTTATACATCTGAT\n",
      "TATCTGGATAGAAACCACAGCA\n",
      "ATTTCTGGCTTGAGCAACAGAG\n",
      "TTAGTGGATTCAGACAACTGCC\n",
      "TCCTTTGGTCACCACCACTGGG\n",
      "AAACAGTGCTTCATCTTCAGCT\n",
      "TGAGCTGATTGGCATAACAGCA\n",
      "GGAAAACACTGTGACCTCAGGA\n"
     ]
    }
   ],
   "source": [
    "for seq in predictions[predictions['targets'] > 4]['seq']:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TGCTAAAATTGTTGCTGCTGTTNNTGCTATTGTTGGTTTTGTTGTT',\n",
       " 'CACTTGAATCCAGGAGGCGGAGNNTGCAGTGAGCCGAGATCACGTC',\n",
       " 'TGCTTGAACCTGGGAGACAGAGNNTGCAGTGAGCCGAGATTGCACC',\n",
       " 'ATGCATGCCTCCTGCAGCTGCANNTTCTGCTGTGGCAGCTGTGTCT',\n",
       " 'CCATGTTTTTAATGCAGCTCAGNNGTCTGTAGTCTGAGGCAGTGAG',\n",
       " 'CTTTGATGTTTTTACTTATGCANNTTCAATTATCTAAGTTCCCTTC']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_dict = {0:'A',1:'T',2:'C',3:'G',4:'N'}\n",
    "translate_func = lambda x: ''.join([trans_dict[y] for y in x])\n",
    "\n",
    "inputs = np.argmax(data, axis=2).numpy()\n",
    "inputs = [translate_func(x) for x in inputs]\n",
    "\n",
    "preds = pd.DataFrame({'inputs':inputs, })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
