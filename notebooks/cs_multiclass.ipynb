{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import genomepy\n",
    "import lightning as L\n",
    "import lightning.pytorch as pl\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Set up path to import parent modules\n",
    "from pathlib import Path\n",
    "import sys  \n",
    "\n",
    "# Add to sys.path\n",
    "sys.path.insert(0, str(Path().resolve().parents[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sequence data from cryptic seq experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.utilities.types import EVAL_DATALOADERS\n",
    "import cryptic.models as models\n",
    "import cryptic.lightning as lit\n",
    "from cryptic.lightning import data_modules, modules\n",
    "from cryptic.models import mlp\n",
    "from cryptic.datasets import data\n",
    "\n",
    "data_path = '../data/TB000208a'\n",
    "genomic_reference_file = '../data/references/hg38.fa'\n",
    "n_classes = 2\n",
    "seq_length = 22\n",
    "vocab_size = 4\n",
    "input_size = seq_length*vocab_size\n",
    "hidden_size = 8\n",
    "n_hidden = 2\n",
    "train_test_split = 0.8\n",
    "\n",
    "data_module = lit.data_modules.DataModule(data_path, n_classes=n_classes, train_test_split=train_test_split, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /var/folders/x8/067mrh2x5_s1x14x3kq4qkd80000gr/T/tmpydaeullk\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /var/folders/x8/067mrh2x5_s1x14x3kq4qkd80000gr/T/tmpydaeullk/_remote_module_non_scriptable.py\n",
      "INFO: GPU available: True (mps), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (mps), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO: \n",
      "  | Name     | Type               | Params\n",
      "------------------------------------------------\n",
      "0 | model    | Model              | 802   \n",
      "1 | sigmoid  | Sigmoid            | 0     \n",
      "2 | loss_fn  | BCEWithLogitsLoss  | 0     \n",
      "3 | accuracy | MulticlassAccuracy | 0     \n",
      "------------------------------------------------\n",
      "802       Trainable params\n",
      "0         Non-trainable params\n",
      "802       Total params\n",
      "0.003     Total estimated model params size (MB)\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name     | Type               | Params\n",
      "------------------------------------------------\n",
      "0 | model    | Model              | 802   \n",
      "1 | sigmoid  | Sigmoid            | 0     \n",
      "2 | loss_fn  | BCEWithLogitsLoss  | 0     \n",
      "3 | accuracy | MulticlassAccuracy | 0     \n",
      "------------------------------------------------\n",
      "802       Trainable params\n",
      "0         Non-trainable params\n",
      "802       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0daebd65834a4105a22b5855294debda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewbakalar/anaconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/matthewbakalar/anaconda3/lib/python3.11/site-packages/torchmetrics/functional/classification/accuracy.py:77: UserWarning: MPS: no support for int64 reduction ops, casting it to int32 (Triggered internally at /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_1aidzjezue/croot/pytorch_1687856425340/work/aten/src/ATen/native/mps/operations/ReduceOps.mm:144.)\n",
      "  tp = tp.sum(dim=0 if multidim_average == \"global\" else 1)\n",
      "/Users/matthewbakalar/anaconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028ed8d0a3d84d72b0a817a87a74ec26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e0a84f26824103a1cd7aeeb8a09825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = models.mlp.Model(input_size=input_size, hidden_size=hidden_size, output_size=n_classes, n_hidden=n_hidden, dropout=0.5)\n",
    "lit_model = modules.Classifier(model, n_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# train the model\n",
    "tb_logger = pl.loggers.TensorBoardLogger(save_dir=\"lightning_logs/\")\n",
    "trainer = pl.Trainer(max_epochs=1, logger=tb_logger, default_root_dir='.')\n",
    "trainer.fit(lit_model, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle '_io.BufferedReader' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred_dataset, num_workers\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m pred_data_module \u001b[39m=\u001b[39m GenomeDataModule(genomic_reference_file)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m preds \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mpredict(lit_model, pred_data_module)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m preds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mhstack(preds[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:865\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mRUNNING\n\u001b[1;32m    864\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m \u001b[39mreturn\u001b[39;00m call\u001b[39m.\u001b[39m_call_and_handle_interrupt(\n\u001b[1;32m    866\u001b[0m     \u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predict_impl, model, dataloaders, datamodule, return_predictions, ckpt_path\n\u001b[1;32m    867\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:904\u001b[0m, in \u001b[0;36mTrainer._predict_impl\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    901\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    902\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn, ckpt_path, model_provided\u001b[39m=\u001b[39mmodel_provided, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    903\u001b[0m )\n\u001b[0;32m--> 904\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run(model, ckpt_path\u001b[39m=\u001b[39mckpt_path)\n\u001b[1;32m    906\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    907\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:990\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    987\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 990\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_stage()\n\u001b[1;32m    992\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    995\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1031\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_loop\u001b[39m.\u001b[39mrun()\n\u001b[1;32m   1030\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[0;32m-> 1031\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_loop\u001b[39m.\u001b[39mrun()\n\u001b[1;32m   1032\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[1;32m   1033\u001b[0m     \u001b[39mwith\u001b[39;00m isolate_rng():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightning/pytorch/loops/utilities.py:181\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[1;32m    180\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 181\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightning/pytorch/loops/prediction_loop.py:105\u001b[0m, in \u001b[0;36m_PredictionLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskip:\n\u001b[1;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n\u001b[1;32m    106\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_run_start()\n\u001b[1;32m    107\u001b[0m data_fetcher \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightning/pytorch/loops/prediction_loop.py:179\u001b[0m, in \u001b[0;36m_PredictionLoop.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m combined_loader\u001b[39m.\u001b[39mlimits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_batches\n\u001b[1;32m    178\u001b[0m data_fetcher\u001b[39m.\u001b[39msetup(combined_loader)\n\u001b[0;32m--> 179\u001b[0m \u001b[39miter\u001b[39m(data_fetcher)  \u001b[39m# creates the iterator inside the fetcher\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[39m# add the previous `fetched` value to properly track `is_last_batch` with no prefetching\u001b[39;00m\n\u001b[1;32m    182\u001b[0m data_fetcher\u001b[39m.\u001b[39mfetched \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mcurrent\u001b[39m.\u001b[39mready\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightning/pytorch/loops/fetchers.py:99\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_PrefetchDataFetcher\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 99\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[1;32m    100\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m         \u001b[39m# ignore pre-fetching, it's not necessary\u001b[39;00m\n\u001b[1;32m    102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightning/pytorch/loops/fetchers.py:48\u001b[0m, in \u001b[0;36m_DataFetcher.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_DataFetcher\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcombined_loader)\n\u001b[1;32m     49\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n\u001b[1;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightning/pytorch/utilities/combined_loader.py:335\u001b[0m, in \u001b[0;36mCombinedLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m _SUPPORTED_MODES[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode][\u001b[39m\"\u001b[39m\u001b[39miterator\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    334\u001b[0m iterator \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflattened, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_limits)\n\u001b[0;32m--> 335\u001b[0m \u001b[39miter\u001b[39m(iterator)\n\u001b[1;32m    336\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator \u001b[39m=\u001b[39m iterator\n\u001b[1;32m    337\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightning/pytorch/utilities/combined_loader.py:144\u001b[0m, in \u001b[0;36m_Sequential.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator_idx \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    143\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_idx \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 144\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_current_iterator()\n\u001b[1;32m    145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightning/pytorch/utilities/combined_loader.py:160\u001b[0m, in \u001b[0;36m_Sequential._load_current_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load_current_iterator\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[39m# Load a single DataLoader, prevents multiple sets of workers from starting unnecessarily\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator_idx \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterables):\n\u001b[0;32m--> 160\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterators \u001b[39m=\u001b[39m [\u001b[39miter\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterables[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator_idx])]\n\u001b[1;32m    161\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m         \u001b[39m# No more iterables to step through, return an empty list\u001b[39;00m\n\u001b[1;32m    163\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterators \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    440\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_iterator()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1042\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1035\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1042\u001b[0m w\u001b[39m.\u001b[39mstart()\n\u001b[1;32m   1043\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Popen(\u001b[39mself\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39mget_context()\u001b[39m.\u001b[39mProcess\u001b[39m.\u001b[39m_Popen(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/context.py:288\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    287\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 288\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_launch(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/popen_spawn_posix.py:47\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, fp)\n\u001b[0;32m---> 47\u001b[0m     reduction\u001b[39m.\u001b[39mdump(process_obj, fp)\n\u001b[1;32m     48\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39mdump(obj)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle '_io.BufferedReader' object"
     ]
    }
   ],
   "source": [
    "# Blazing fast prediction code. Currently runs on one chromosome only\n",
    "\n",
    "from cryptic.datasets.data import GenomeBoxcarDataset\n",
    "\n",
    "genomic_reference_file = '../../data/reference/hg38.fa'\n",
    "\n",
    "class GenomeDataModule(L.LightningDataModule):\n",
    "    def __init__(self, data_file, batch_size=256):\n",
    "        super().__init__()\n",
    "        self.data_file = data_file\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        if stage == 'predict':\n",
    "            self.pred_dataset = GenomeBoxcarDataset(fasta_file=self.data_file)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.pred_dataset, batch_size=self.batch_size)\n",
    "\n",
    "pred_data_module = GenomeDataModule(genomic_reference_file)\n",
    "preds = trainer.predict(lit_model, pred_data_module)\n",
    "preds = torch.hstack(preds[:-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chr1...\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "550000\n",
      "560000\n",
      "570000\n",
      "580000\n",
      "590000\n",
      "600000\n",
      "610000\n",
      "620000\n",
      "630000\n",
      "640000\n",
      "650000\n",
      "660000\n",
      "670000\n",
      "680000\n",
      "690000\n",
      "700000\n",
      "710000\n",
      "720000\n",
      "730000\n",
      "740000\n",
      "750000\n",
      "760000\n",
      "770000\n",
      "780000\n",
      "790000\n",
      "800000\n",
      "810000\n",
      "820000\n",
      "830000\n",
      "840000\n",
      "850000\n",
      "860000\n",
      "870000\n",
      "880000\n",
      "890000\n",
      "900000\n",
      "910000\n",
      "920000\n",
      "930000\n",
      "940000\n",
      "950000\n",
      "960000\n",
      "970000\n",
      "980000\n",
      "990000\n",
      "1000000\n",
      "1010000\n",
      "1020000\n",
      "1030000\n",
      "1040000\n",
      "1050000\n",
      "1060000\n",
      "1070000\n",
      "1080000\n",
      "1090000\n",
      "1100000\n",
      "1110000\n",
      "1120000\n",
      "1130000\n",
      "1140000\n",
      "1150000\n",
      "1160000\n",
      "1170000\n",
      "1180000\n",
      "1190000\n",
      "1200000\n",
      "1210000\n",
      "1220000\n",
      "1230000\n",
      "1240000\n",
      "1250000\n",
      "1260000\n",
      "1270000\n",
      "1280000\n",
      "1290000\n",
      "1300000\n",
      "1310000\n",
      "1320000\n",
      "1330000\n",
      "1340000\n",
      "1350000\n",
      "1360000\n",
      "1370000\n",
      "1380000\n",
      "1390000\n",
      "1400000\n",
      "1410000\n",
      "1420000\n",
      "1430000\n",
      "1440000\n",
      "1450000\n",
      "1460000\n",
      "1470000\n",
      "1480000\n",
      "1490000\n",
      "1500000\n",
      "1510000\n",
      "1520000\n",
      "1530000\n",
      "1540000\n",
      "1550000\n",
      "1560000\n",
      "1570000\n",
      "1580000\n",
      "1590000\n",
      "1600000\n",
      "1610000\n",
      "1620000\n",
      "1630000\n",
      "1640000\n",
      "1650000\n",
      "1660000\n",
      "1670000\n",
      "1680000\n",
      "1690000\n",
      "1700000\n",
      "1710000\n",
      "1720000\n",
      "1730000\n",
      "1740000\n",
      "1750000\n",
      "1760000\n",
      "1770000\n",
      "1780000\n",
      "1790000\n",
      "1800000\n",
      "1810000\n",
      "1820000\n",
      "1830000\n",
      "1840000\n",
      "1850000\n",
      "1860000\n",
      "1870000\n",
      "1880000\n",
      "1890000\n",
      "1900000\n",
      "1910000\n",
      "1920000\n",
      "1930000\n",
      "1940000\n",
      "1950000\n",
      "1960000\n",
      "1970000\n",
      "1980000\n",
      "1990000\n",
      "2000000\n",
      "2010000\n",
      "2020000\n",
      "2030000\n",
      "2040000\n",
      "2050000\n",
      "2060000\n",
      "2070000\n",
      "2080000\n",
      "2090000\n",
      "2100000\n",
      "2110000\n",
      "2120000\n",
      "2130000\n",
      "2140000\n",
      "2150000\n",
      "2160000\n",
      "2170000\n",
      "2180000\n",
      "2190000\n",
      "2200000\n",
      "2210000\n",
      "2220000\n",
      "2230000\n",
      "2240000\n",
      "2250000\n",
      "2260000\n",
      "2270000\n",
      "2280000\n",
      "2290000\n",
      "2300000\n",
      "2310000\n",
      "2320000\n",
      "2330000\n",
      "2340000\n",
      "2350000\n",
      "2360000\n",
      "2370000\n",
      "2380000\n",
      "2390000\n",
      "2400000\n",
      "2410000\n",
      "2420000\n",
      "2430000\n",
      "2440000\n",
      "2450000\n",
      "2460000\n",
      "2470000\n",
      "2480000\n",
      "2490000\n",
      "2500000\n",
      "2510000\n",
      "2520000\n",
      "2530000\n",
      "2540000\n",
      "2550000\n",
      "2560000\n",
      "2570000\n",
      "2580000\n",
      "2590000\n",
      "2600000\n",
      "2610000\n",
      "2620000\n",
      "2630000\n",
      "2640000\n",
      "2650000\n",
      "2660000\n",
      "2670000\n",
      "2680000\n",
      "2690000\n",
      "2700000\n",
      "2710000\n",
      "2720000\n",
      "2730000\n",
      "2740000\n",
      "2750000\n",
      "2760000\n",
      "2770000\n",
      "2780000\n",
      "2790000\n",
      "2800000\n",
      "2810000\n",
      "2820000\n",
      "2830000\n",
      "2840000\n",
      "2850000\n",
      "2860000\n",
      "2870000\n",
      "2880000\n",
      "2890000\n",
      "2900000\n",
      "2910000\n",
      "2920000\n",
      "2930000\n",
      "2940000\n",
      "2950000\n",
      "2960000\n",
      "2970000\n",
      "2980000\n",
      "2990000\n",
      "3000000\n",
      "3010000\n",
      "3020000\n",
      "3030000\n",
      "3040000\n",
      "3050000\n",
      "3060000\n",
      "3070000\n",
      "3080000\n",
      "3090000\n",
      "3100000\n",
      "3110000\n",
      "3120000\n",
      "3130000\n",
      "3140000\n",
      "3150000\n",
      "3160000\n",
      "3170000\n",
      "3180000\n",
      "3190000\n",
      "3200000\n",
      "3210000\n",
      "3220000\n",
      "3230000\n",
      "3240000\n",
      "3250000\n",
      "3260000\n",
      "3270000\n",
      "3280000\n",
      "3290000\n",
      "3300000\n",
      "3310000\n",
      "3320000\n",
      "3330000\n",
      "3340000\n",
      "3350000\n",
      "3360000\n",
      "3370000\n",
      "3380000\n",
      "3390000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb Cell 12\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m chromosome_id \u001b[39m=\u001b[39m record\u001b[39m.\u001b[39mid\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing \u001b[39m\u001b[39m{\u001b[39;00mchromosome_id\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m predictions \u001b[39m=\u001b[39m sliding_window_inference(\u001b[39mstr\u001b[39m(chromosome_sequence), seq_length, batch_size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39mprint\u001b[39m(predictions)\n",
      "\u001b[1;32m/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m back_half_sequence \u001b[39m=\u001b[39m reverse_complement(full_sequence[\u001b[39m24\u001b[39m:])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m encoded_seqs_front\u001b[39m.\u001b[39mappend(encode_sequence(front_half_sequence, seq_length))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m encoded_seqs_back\u001b[39m.\u001b[39mappend(encode_sequence(back_half_sequence, seq_length))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoded_seqs_front) \u001b[39m==\u001b[39m batch_size:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39m# Make predictions on batch\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     batch_preds \u001b[39m=\u001b[39m predict_on_batch(encoded_seqs_front, encoded_seqs_back)\n",
      "\u001b[1;32m/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m translation_dict \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mA\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m0\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mT\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m1\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m2\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mG\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m3\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mN\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m4\u001b[39m}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m encoding \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([translation_dict[c] \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m seq])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mone_hot(encoding, num_classes\u001b[39m=\u001b[39mvocab_size)\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load checkpoint\n",
    "\n",
    "lit_model.eval()\n",
    "\n",
    "from Bio import SeqIO  #\n",
    "import torch.nn.functional as F\n",
    "\n",
    "genomic_reference_file = '../../data/reference/hg38.fa'\n",
    "\n",
    "\n",
    "def reverse_complement(dna_sequence):\n",
    "    complement = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C'}\n",
    "    reversed_sequence = dna_sequence[::-1]\n",
    "    reverse_complement_sequence = ''.join(complement[nucleotide] for nucleotide in reversed_sequence)\n",
    "    return reverse_complement_sequence\n",
    "\n",
    "def encode_sequence(seq, seq_length=46, vocab_size=5):\n",
    "    translation_dict = {'A':0,'T':1,'C':2,'G':3,'N':4}\n",
    "    encoding = torch.tensor([translation_dict[c] for c in seq])\n",
    "    x = F.one_hot(encoding, num_classes=vocab_size).to(torch.float32)\n",
    "    return x\n",
    "\n",
    "# Adjust the sliding window function to use batches\n",
    "def sliding_window_inference(genome_sequence, seq_length, batch_size):\n",
    "    predictions = []\n",
    "    encoded_seqs_front = []\n",
    "    encoded_seqs_back = []\n",
    "    \n",
    "    for i in range(0, len(genome_sequence) - seq_length + 1):\n",
    "        if i % 10000 == 0:\n",
    "            print(i)\n",
    "        # Check for 'N' early\n",
    "        full_sequence = genome_sequence[i:i+seq_length]\n",
    "        if 'N' in full_sequence:\n",
    "            continue\n",
    "        \n",
    "        # Process in batches\n",
    "        front_half_sequence = full_sequence[:22]\n",
    "        back_half_sequence = reverse_complement(full_sequence[24:])\n",
    "        \n",
    "        encoded_seqs_front.append(encode_sequence(front_half_sequence, seq_length))\n",
    "        encoded_seqs_back.append(encode_sequence(back_half_sequence, seq_length))\n",
    "        \n",
    "        if len(encoded_seqs_front) == batch_size:\n",
    "            # Make predictions on batch\n",
    "            batch_preds = predict_on_batch(encoded_seqs_front, encoded_seqs_back)\n",
    "            predictions.extend(batch_preds)\n",
    "            \n",
    "            # Clear lists for next batch\n",
    "            encoded_seqs_front = []\n",
    "            encoded_seqs_back = []\n",
    "\n",
    "    # Process the final batch if there are any sequences left\n",
    "    if encoded_seqs_front:\n",
    "        batch_preds = predict_on_batch(encoded_seqs_front, encoded_seqs_back)\n",
    "        predictions.extend(batch_preds)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Define a function to make predictions on batches\n",
    "def predict_on_batch(front_seqs, back_seqs):\n",
    "    front_seqs_tensor = torch.stack(front_seqs)\n",
    "    back_seqs_tensor = torch.stack(back_seqs)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        front_preds = lit_model.predict_step((front_seqs_tensor, None), 0)\n",
    "        back_preds = lit_model.predict_step((back_seqs_tensor, None), 0)\n",
    "        average_logits = (front_preds + back_preds) / 2\n",
    "        sigmoid = torch.nn.Sigmoid()\n",
    "        final_preds = sigmoid(average_logits)\n",
    "    \n",
    "    # print(final_preds)\n",
    "        \n",
    "    return final_preds.tolist()\n",
    "\n",
    "\n",
    "# Process each sequence in the FASTA file\n",
    "seq_length = 46\n",
    "batch_size = 10000  # or any size that fits in your GPU memory\n",
    "for record in SeqIO.parse(genomic_reference_file, \"fasta\"):\n",
    "    chromosome_sequence = record.seq.upper()\n",
    "    chromosome_id = record.id\n",
    "    print(f\"Processing {chromosome_id}...\")\n",
    "    \n",
    "    predictions = sliding_window_inference(str(chromosome_sequence), seq_length, batch_size)\n",
    "    print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix this to unzip a tuple\n",
    "data = list(data_module.predict_dataloader())\n",
    "inputs, labels = map(list, zip(*data))\n",
    "inputs = torch.vstack(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
