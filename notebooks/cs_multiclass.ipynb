{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "# Set up path to import parent modules\n",
    "from pathlib import Path\n",
    "import sys  \n",
    "\n",
    "# Add to sys.path\n",
    "sys.path.insert(0, str(Path().resolve().parents[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type               | Params\n",
      "------------------------------------------------\n",
      "0 | model    | MLPModel           | 358 K \n",
      "1 | sigmoid  | Sigmoid            | 0     \n",
      "2 | loss_fn  | BCEWithLogitsLoss  | 0     \n",
      "3 | accuracy | MulticlassAccuracy | 0     \n",
      "------------------------------------------------\n",
      "358 K     Trainable params\n",
      "0         Non-trainable params\n",
      "358 K     Total params\n",
      "1.434     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2072d153dce436681abc72d5ba3b6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewbakalar/anaconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/matthewbakalar/anaconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67266451ad904209987e9434906740af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010b688494d64877b0a192cceaba4465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d6c1200357430ea269a94b5675a30b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d284305b9e17408394d3a283f04febaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ccb50d5086d4d30ba760b08079cfc64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af033480ade34780ac51354eef6f5475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "import cryptic.models as models\n",
    "from cryptic.lit_modules import data_modules, modules\n",
    "from cryptic.models import models\n",
    "\n",
    "data_path = '../data/TB000208a'\n",
    "genomic_reference_file = '../data/references/hg38.fa'\n",
    "n_classes = 2\n",
    "seq_length = 46\n",
    "vocab_size = 4\n",
    "input_size = seq_length*vocab_size\n",
    "hidden_size = 512\n",
    "n_hidden = 2\n",
    "train_test_split = 0.8\n",
    "\n",
    "# Build the data module\n",
    "data_module = data_modules.MulticlassDataModule(data_path, threshold=0.01, n_classes=n_classes, train_test_split=train_test_split, batch_size=32)\n",
    "\n",
    "# Build model\n",
    "model = models.MLPModel(input_size=input_size, hidden_size=hidden_size, output_size=n_classes, n_hidden=n_hidden, dropout=0.5)\n",
    "lit_model = modules.Classifier(model, n_classes)\n",
    "\n",
    "# train the model\n",
    "tb_logger = pl.loggers.TensorBoardLogger(save_dir=\"lightning_logs/\")\n",
    "trainer = pl.Trainer(max_epochs=5, logger=tb_logger, default_root_dir='.')\n",
    "trainer.fit(lit_model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewbakalar/anaconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03459d3af554db2aee7ba5bf11b9415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_acc_step         0.7878776788711548\n",
      "        test_loss            0.526176929473877\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc_step': 0.7878776788711548, 'test_loss': 0.526176929473877}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(lit_model, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewbakalar/anaconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f79316b7b5f4acd828e17abb0127e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewbakalar/anaconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb Cell 7\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m pred_data_module \u001b[39m=\u001b[39m data_modules\u001b[39m.\u001b[39mGenomeDataModule(genomic_reference_file, batch_size\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m preds \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mpredict(lit_model, pred_data_module)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m preds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mhstack(preds[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Fast prediction code. Currently runs on one chromosome only\n",
    "genomic_reference_file = '../../data/reference/hg38.fa'\n",
    "\n",
    "pred_data_module = data_modules.GenomeDataModule(genomic_reference_file, batch_size=256)\n",
    "preds = trainer.predict(lit_model, pred_data_module)\n",
    "preds = torch.hstack(preds[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chr1...\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "550000\n",
      "560000\n",
      "570000\n",
      "580000\n",
      "590000\n",
      "600000\n",
      "610000\n",
      "620000\n",
      "630000\n",
      "640000\n",
      "650000\n",
      "660000\n",
      "670000\n",
      "680000\n",
      "690000\n",
      "700000\n",
      "710000\n",
      "720000\n",
      "730000\n",
      "740000\n",
      "750000\n",
      "760000\n",
      "770000\n",
      "780000\n",
      "790000\n",
      "800000\n",
      "810000\n",
      "820000\n",
      "830000\n",
      "840000\n",
      "850000\n",
      "860000\n",
      "870000\n",
      "880000\n",
      "890000\n",
      "900000\n",
      "910000\n",
      "920000\n",
      "930000\n",
      "940000\n",
      "950000\n",
      "960000\n",
      "970000\n",
      "980000\n",
      "990000\n",
      "1000000\n",
      "1010000\n",
      "1020000\n",
      "1030000\n",
      "1040000\n",
      "1050000\n",
      "1060000\n",
      "1070000\n",
      "1080000\n",
      "1090000\n",
      "1100000\n",
      "1110000\n",
      "1120000\n",
      "1130000\n",
      "1140000\n",
      "1150000\n",
      "1160000\n",
      "1170000\n",
      "1180000\n",
      "1190000\n",
      "1200000\n",
      "1210000\n",
      "1220000\n",
      "1230000\n",
      "1240000\n",
      "1250000\n",
      "1260000\n",
      "1270000\n",
      "1280000\n",
      "1290000\n",
      "1300000\n",
      "1310000\n",
      "1320000\n",
      "1330000\n",
      "1340000\n",
      "1350000\n",
      "1360000\n",
      "1370000\n",
      "1380000\n",
      "1390000\n",
      "1400000\n",
      "1410000\n",
      "1420000\n",
      "1430000\n",
      "1440000\n",
      "1450000\n",
      "1460000\n",
      "1470000\n",
      "1480000\n",
      "1490000\n",
      "1500000\n",
      "1510000\n",
      "1520000\n",
      "1530000\n",
      "1540000\n",
      "1550000\n",
      "1560000\n",
      "1570000\n",
      "1580000\n",
      "1590000\n",
      "1600000\n",
      "1610000\n",
      "1620000\n",
      "1630000\n",
      "1640000\n",
      "1650000\n",
      "1660000\n",
      "1670000\n",
      "1680000\n",
      "1690000\n",
      "1700000\n",
      "1710000\n",
      "1720000\n",
      "1730000\n",
      "1740000\n",
      "1750000\n",
      "1760000\n",
      "1770000\n",
      "1780000\n",
      "1790000\n",
      "1800000\n",
      "1810000\n",
      "1820000\n",
      "1830000\n",
      "1840000\n",
      "1850000\n",
      "1860000\n",
      "1870000\n",
      "1880000\n",
      "1890000\n",
      "1900000\n",
      "1910000\n",
      "1920000\n",
      "1930000\n",
      "1940000\n",
      "1950000\n",
      "1960000\n",
      "1970000\n",
      "1980000\n",
      "1990000\n",
      "2000000\n",
      "2010000\n",
      "2020000\n",
      "2030000\n",
      "2040000\n",
      "2050000\n",
      "2060000\n",
      "2070000\n",
      "2080000\n",
      "2090000\n",
      "2100000\n",
      "2110000\n",
      "2120000\n",
      "2130000\n",
      "2140000\n",
      "2150000\n",
      "2160000\n",
      "2170000\n",
      "2180000\n",
      "2190000\n",
      "2200000\n",
      "2210000\n",
      "2220000\n",
      "2230000\n",
      "2240000\n",
      "2250000\n",
      "2260000\n",
      "2270000\n",
      "2280000\n",
      "2290000\n",
      "2300000\n",
      "2310000\n",
      "2320000\n",
      "2330000\n",
      "2340000\n",
      "2350000\n",
      "2360000\n",
      "2370000\n",
      "2380000\n",
      "2390000\n",
      "2400000\n",
      "2410000\n",
      "2420000\n",
      "2430000\n",
      "2440000\n",
      "2450000\n",
      "2460000\n",
      "2470000\n",
      "2480000\n",
      "2490000\n",
      "2500000\n",
      "2510000\n",
      "2520000\n",
      "2530000\n",
      "2540000\n",
      "2550000\n",
      "2560000\n",
      "2570000\n",
      "2580000\n",
      "2590000\n",
      "2600000\n",
      "2610000\n",
      "2620000\n",
      "2630000\n",
      "2640000\n",
      "2650000\n",
      "2660000\n",
      "2670000\n",
      "2680000\n",
      "2690000\n",
      "2700000\n",
      "2710000\n",
      "2720000\n",
      "2730000\n",
      "2740000\n",
      "2750000\n",
      "2760000\n",
      "2770000\n",
      "2780000\n",
      "2790000\n",
      "2800000\n",
      "2810000\n",
      "2820000\n",
      "2830000\n",
      "2840000\n",
      "2850000\n",
      "2860000\n",
      "2870000\n",
      "2880000\n",
      "2890000\n",
      "2900000\n",
      "2910000\n",
      "2920000\n",
      "2930000\n",
      "2940000\n",
      "2950000\n",
      "2960000\n",
      "2970000\n",
      "2980000\n",
      "2990000\n",
      "3000000\n",
      "3010000\n",
      "3020000\n",
      "3030000\n",
      "3040000\n",
      "3050000\n",
      "3060000\n",
      "3070000\n",
      "3080000\n",
      "3090000\n",
      "3100000\n",
      "3110000\n",
      "3120000\n",
      "3130000\n",
      "3140000\n",
      "3150000\n",
      "3160000\n",
      "3170000\n",
      "3180000\n",
      "3190000\n",
      "3200000\n",
      "3210000\n",
      "3220000\n",
      "3230000\n",
      "3240000\n",
      "3250000\n",
      "3260000\n",
      "3270000\n",
      "3280000\n",
      "3290000\n",
      "3300000\n",
      "3310000\n",
      "3320000\n",
      "3330000\n",
      "3340000\n",
      "3350000\n",
      "3360000\n",
      "3370000\n",
      "3380000\n",
      "3390000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb Cell 12\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m chromosome_id \u001b[39m=\u001b[39m record\u001b[39m.\u001b[39mid\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing \u001b[39m\u001b[39m{\u001b[39;00mchromosome_id\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m predictions \u001b[39m=\u001b[39m sliding_window_inference(\u001b[39mstr\u001b[39m(chromosome_sequence), seq_length, batch_size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39mprint\u001b[39m(predictions)\n",
      "\u001b[1;32m/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m back_half_sequence \u001b[39m=\u001b[39m reverse_complement(full_sequence[\u001b[39m24\u001b[39m:])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m encoded_seqs_front\u001b[39m.\u001b[39mappend(encode_sequence(front_half_sequence, seq_length))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m encoded_seqs_back\u001b[39m.\u001b[39mappend(encode_sequence(back_half_sequence, seq_length))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoded_seqs_front) \u001b[39m==\u001b[39m batch_size:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39m# Make predictions on batch\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     batch_preds \u001b[39m=\u001b[39m predict_on_batch(encoded_seqs_front, encoded_seqs_back)\n",
      "\u001b[1;32m/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m translation_dict \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mA\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m0\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mT\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m1\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m2\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mG\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m3\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mN\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m4\u001b[39m}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m encoding \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([translation_dict[c] \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m seq])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mone_hot(encoding, num_classes\u001b[39m=\u001b[39mvocab_size)\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewbakalar/Documents/Code/cryptic/Notebooks/cs_multiclass.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load checkpoint\n",
    "\n",
    "lit_model.eval()\n",
    "\n",
    "from Bio import SeqIO  #\n",
    "import torch.nn.functional as F\n",
    "\n",
    "genomic_reference_file = '../../data/reference/hg38.fa'\n",
    "\n",
    "\n",
    "def reverse_complement(dna_sequence):\n",
    "    complement = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C'}\n",
    "    reversed_sequence = dna_sequence[::-1]\n",
    "    reverse_complement_sequence = ''.join(complement[nucleotide] for nucleotide in reversed_sequence)\n",
    "    return reverse_complement_sequence\n",
    "\n",
    "def encode_sequence(seq, seq_length=46, vocab_size=5):\n",
    "    translation_dict = {'A':0,'T':1,'C':2,'G':3,'N':4}\n",
    "    encoding = torch.tensor([translation_dict[c] for c in seq])\n",
    "    x = F.one_hot(encoding, num_classes=vocab_size).to(torch.float32)\n",
    "    return x\n",
    "\n",
    "# Adjust the sliding window function to use batches\n",
    "def sliding_window_inference(genome_sequence, seq_length, batch_size):\n",
    "    predictions = []\n",
    "    encoded_seqs_front = []\n",
    "    encoded_seqs_back = []\n",
    "    \n",
    "    for i in range(0, len(genome_sequence) - seq_length + 1):\n",
    "        if i % 10000 == 0:\n",
    "            print(i)\n",
    "        # Check for 'N' early\n",
    "        full_sequence = genome_sequence[i:i+seq_length]\n",
    "        if 'N' in full_sequence:\n",
    "            continue\n",
    "        \n",
    "        # Process in batches\n",
    "        front_half_sequence = full_sequence[:22]\n",
    "        back_half_sequence = reverse_complement(full_sequence[24:])\n",
    "        \n",
    "        encoded_seqs_front.append(encode_sequence(front_half_sequence, seq_length))\n",
    "        encoded_seqs_back.append(encode_sequence(back_half_sequence, seq_length))\n",
    "        \n",
    "        if len(encoded_seqs_front) == batch_size:\n",
    "            # Make predictions on batch\n",
    "            batch_preds = predict_on_batch(encoded_seqs_front, encoded_seqs_back)\n",
    "            predictions.extend(batch_preds)\n",
    "            \n",
    "            # Clear lists for next batch\n",
    "            encoded_seqs_front = []\n",
    "            encoded_seqs_back = []\n",
    "\n",
    "    # Process the final batch if there are any sequences left\n",
    "    if encoded_seqs_front:\n",
    "        batch_preds = predict_on_batch(encoded_seqs_front, encoded_seqs_back)\n",
    "        predictions.extend(batch_preds)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Define a function to make predictions on batches\n",
    "def predict_on_batch(front_seqs, back_seqs):\n",
    "    front_seqs_tensor = torch.stack(front_seqs)\n",
    "    back_seqs_tensor = torch.stack(back_seqs)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        front_preds = lit_model.predict_step((front_seqs_tensor, None), 0)\n",
    "        back_preds = lit_model.predict_step((back_seqs_tensor, None), 0)\n",
    "        average_logits = (front_preds + back_preds) / 2\n",
    "        sigmoid = torch.nn.Sigmoid()\n",
    "        final_preds = sigmoid(average_logits)\n",
    "    \n",
    "    # print(final_preds)\n",
    "        \n",
    "    return final_preds.tolist()\n",
    "\n",
    "\n",
    "# Process each sequence in the FASTA file\n",
    "seq_length = 46\n",
    "batch_size = 10000  # or any size that fits in your GPU memory\n",
    "for record in SeqIO.parse(genomic_reference_file, \"fasta\"):\n",
    "    chromosome_sequence = record.seq.upper()\n",
    "    chromosome_id = record.id\n",
    "    print(f\"Processing {chromosome_id}...\")\n",
    "    \n",
    "    predictions = sliding_window_inference(str(chromosome_sequence), seq_length, batch_size)\n",
    "    print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix this to unzip a tuple\n",
    "data = list(data_module.predict_dataloader())\n",
    "inputs, labels = map(list, zip(*data))\n",
    "inputs = torch.vstack(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
